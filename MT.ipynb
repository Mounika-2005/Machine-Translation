{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F_WzeZuKgWWQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecae5c3e-743c-4b3c-c7b6-da3d9e620f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qj9wh4_ol9_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e01edc8-2268-43f8-926d-185d494088a9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "with open('/content/gdrive/MyDrive/V2/4L.kn.txt') as mf:\n",
        "    lines = mf.readlines()\n",
        "\n",
        "len(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvZZor3EysMQ",
        "outputId": "d1c5c9b4-4cca-4546-99c1-4770cd5fed39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "with open('/content/gdrive/MyDrive/V2/4L.en.txt') as mf:\n",
        "    lines = mf.readlines()\n",
        "\n",
        "len(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xS7IrNuRSH4"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/MyDrive/V2/1L.infer.en.txt') as mf:\n",
        "    lines = mf.readlines()\n",
        "f=open('inf.txt','a')    \n",
        "\n",
        "for i in range(0,100000):\n",
        "  #print(lines[i])\n",
        "  f.write(lines[i])\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0NzzMDyl-Mo"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/MyDrive/V2/4L.en.txt') as mf:\n",
        "    lines = mf.readlines()\n",
        "\n",
        "f=open('src_train.txt','a')\n",
        "\n",
        "for i in range(0,300000):\n",
        "  #print(lines[i])\n",
        "  f.write(lines[i])\n",
        "f.close()\n",
        "\n",
        "fa=open('src_val.txt','a')\n",
        "\n",
        "for i in range(300001,400000):\n",
        "  #print(lines[i])\n",
        "  fa.write(lines[i])\n",
        "fa.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jA4gGzyOkHXm"
      },
      "outputs": [],
      "source": [
        "with open('/content/gdrive/MyDrive/V2/4L.kn.txt') as mf:\n",
        "    lines = mf.readlines()\n",
        "\n",
        "f=open('tgt_train.txt','a')\n",
        "\n",
        "for i in range(0,300000):\n",
        "  #print(lines[i])\n",
        "  f.write(lines[i])\n",
        "f.close()\n",
        "\n",
        "fa=open('tgt_val.txt','a')\n",
        "\n",
        "for i in range(300001,400000):\n",
        "  #print(lines[i])\n",
        "  fa.write(lines[i])\n",
        "fa.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJHspT4KaqKw",
        "outputId": "19bb174c-7dc4-461e-f2d6-f5a56c5b9ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting OpenNMT-tf[tensorflow]\n",
            "  Downloading OpenNMT_tf-2.30.0-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.8/dist-packages (from OpenNMT-tf[tensorflow]) (6.0)\n",
            "Collecting sacrebleu<2.3,>=1.5.0\n",
            "  Downloading sacrebleu-2.2.1-py3-none-any.whl (116 kB)\n",
            "\u001b[K     |████████████████████████████████| 116 kB 71.8 MB/s \n",
            "\u001b[?25hCollecting ctranslate2<4,>=3.0\n",
            "  Downloading ctranslate2-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 30.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting rouge<2,>=1.0\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting tensorflow-addons<0.20,>=0.16\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 57.4 MB/s \n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.29.0\n",
            "  Downloading pyonmttok-1.35.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.7 MB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from OpenNMT-tf[tensorflow]) (21.3)\n",
            "Requirement already satisfied: tensorflow<2.12.0,>=2.6.0 in /usr/local/lib/python3.8/dist-packages (from OpenNMT-tf[tensorflow]) (2.9.2)\n",
            "Collecting tensorflow-text<2.12.0,>=2.6.0\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from ctranslate2<4,>=3.0->OpenNMT-tf[tensorflow]) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from rouge<2,>=1.0->OpenNMT-tf[tensorflow]) (1.15.0)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<2.3,>=1.5.0->OpenNMT-tf[tensorflow]) (2022.6.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu<2.3,>=1.5.0->OpenNMT-tf[tensorflow]) (4.9.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<2.3,>=1.5.0->OpenNMT-tf[tensorflow]) (0.8.10)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.12)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.28.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.19.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (14.0.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (4.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (2022.12.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (3.2.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons<0.20,>=0.16->OpenNMT-tf[tensorflow]) (2.7.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text<2.12.0,>=2.6.0->OpenNMT-tf[tensorflow]) (0.12.0)\n",
            "Collecting tensorflow<2.12.0,>=2.6.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 22 kB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-text<2.12.0,>=2.6.0\n",
            "  Downloading tensorflow_text-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 61.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow<2.12.0,>=2.6.0\n",
            "  Downloading tensorflow-2.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 8.9 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.1 MB 6.7 kB/s \n",
            "\u001b[?25hCollecting tensorflow-text<2.12.0,>=2.6.0\n",
            "  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 66.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->OpenNMT-tf[tensorflow]) (3.0.9)\n",
            "Installing collected packages: portalocker, colorama, tensorflow-addons, sacrebleu, rouge, pyonmttok, ctranslate2, tensorflow-text, OpenNMT-tf\n",
            "Successfully installed OpenNMT-tf-2.30.0 colorama-0.4.6 ctranslate2-3.2.0 portalocker-2.6.0 pyonmttok-1.35.0 rouge-1.0.1 sacrebleu-2.2.1 tensorflow-addons-0.19.0 tensorflow-text-2.9.0\n"
          ]
        }
      ],
      "source": [
        " !pip install OpenNMT-tf[tensorflow]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMTEWKxJaEfb",
        "outputId": "d0496d75-4516-4f8f-b110-eb8b73d7eda6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-build-vocab\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/bin/build_vocab.py\", line 153, in main\n",
            "    vocab.add_from_text(data_file, tokenizer=tokenizer)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 87, in add_from_text\n",
            "    for line in text:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 203, in __next__\n",
            "    retval = self.readline()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 167, in readline\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 76, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/src_train.txt; No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!onmt-build-vocab --size 40000 --save_vocab ./vocab.src /content/src_train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7rlDQFNofrB",
        "outputId": "9097a62b-b026-480c-ede1-cc8a51072ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-build-vocab\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/bin/build_vocab.py\", line 153, in main\n",
            "    vocab.add_from_text(data_file, tokenizer=tokenizer)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 87, in add_from_text\n",
            "    for line in text:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 203, in __next__\n",
            "    retval = self.readline()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 167, in readline\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 76, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/tgt_train.txt; No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!onmt-build-vocab --size 40000 --save_vocab ./vocab.tgt /content/tgt_train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgfhVP5sru3A",
        "outputId": "319e1957-8efb-4adc-c548-9be66c6bb23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "\n",
            "data:\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  eval_features_file: /content/gdrive/MyDrive/MT/src_val.txt\n",
            "  eval_labels_file: /content/gdrive/MyDrive/MT/tgt_infer.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "train:\n",
            "  save_checkpoints_steps: 1000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "eval:\n",
            "  external_evaluators: BLEU\n",
            "params:\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "  learning_rate: 3.0\n",
            "  dropout: 0.3\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  "
          ]
        }
      ],
      "source": [
        "data= \"\"\"model_dir: /content/gdrive/MyDrive/MT\n",
        "\n",
        "data:\n",
        "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
        "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
        "  eval_features_file: /content/gdrive/MyDrive/MT/src_val.txt\n",
        "  eval_labels_file: /content/gdrive/MyDrive/MT/tgt_infer.txt\n",
        "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
        "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
        "train:\n",
        "  save_checkpoints_steps: 1000\n",
        "  maximum_features_length: 50\n",
        "  maximum_labels_length: 50\n",
        "eval:\n",
        "  external_evaluators: BLEU\n",
        "params:\n",
        "  optimizer: Adam\n",
        "  optimizer_params:\n",
        "    beta_1: 0.8\n",
        "    beta_2: 0.998\n",
        "  learning_rate: 3.0\n",
        "  dropout: 0.3\n",
        "infer:\n",
        "  batch_size: 32\n",
        "  \"\"\"\n",
        "with open(\"data.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(data)\n",
        "!cat data.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjSiPWjruCyV"
      },
      "source": [
        "#training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK5XknUWaiMM",
        "outputId": "d9fdeba3-fb11-4226-a264-8de61414eea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: onmt-main\n",
            "       [-h]\n",
            "       [-v]\n",
            "       --config\n",
            "       CONFIG\n",
            "       [CONFIG ...]\n",
            "       [--model_dir MODEL_DIR]\n",
            "       [--auto_config]\n",
            "       [--model_type {GPT2Small,ListenAttendSpell,LstmCnnCrfTagger,LuongAttention,NMTBigV1,NMTMediumV1,NMTSmallV1,ScalingNmtEnDe,ScalingNmtEnFr,Transformer,TransformerBase,TransformerBaseRelative,TransformerBaseSharedEmbeddings,TransformerBig,TransformerBigRelative,TransformerBigSharedEmbeddings,TransformerRelative,TransformerTiny}]\n",
            "       [--model MODEL]\n",
            "       [--run_dir RUN_DIR]\n",
            "       [--data_dir DATA_DIR]\n",
            "       [--checkpoint_path CHECKPOINT_PATH]\n",
            "       [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]\n",
            "       [--seed SEED]\n",
            "       [--gpu_allow_growth]\n",
            "       [--intra_op_parallelism_threads INTRA_OP_PARALLELISM_THREADS]\n",
            "       [--inter_op_parallelism_threads INTER_OP_PARALLELISM_THREADS]\n",
            "       [--mixed_precision]\n",
            "       [--eager_execution]\n",
            "       {train,eval,infer,export,score,average_checkpoints,update_vocab}\n",
            "       ...\n",
            "onmt-main: error: argument --model_type: invalid choice: 'Transformer--config' (choose from 'GPT2Small', 'ListenAttendSpell', 'LstmCnnCrfTagger', 'LuongAttention', 'NMTBigV1', 'NMTMediumV1', 'NMTSmallV1', 'ScalingNmtEnDe', 'ScalingNmtEnFr', 'Transformer', 'TransformerBase', 'TransformerBaseRelative', 'TransformerBaseSharedEmbeddings', 'TransformerBig', 'TransformerBigRelative', 'TransformerBigSharedEmbeddings', 'TransformerRelative', 'TransformerTiny')\n"
          ]
        }
      ],
      "source": [
        "!onmt-main --model_type Transformer--config data.yaml --auto_config train --with_eval "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbyXGvavuIn3"
      },
      "source": [
        "#Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMIiXCz5i8eO",
        "outputId": "b9b9932a-e34b-4e62-f195-33d41e0c5071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-31 07:07:56.952000: I main.py:302] Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "INFO:tensorflow:Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "2022-12-31 07:07:57.677000: I main.py:309] Using OpenNMT-tf version 2.30.0\n",
            "INFO:tensorflow:Using OpenNMT-tf version 2.30.0\n",
            "2022-12-31 07:07:57.677000: I main.py:309] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "INFO:tensorflow:Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2022-12-31 07:07:57.770000: I main.py:333] Using parameters:\n",
            "data:\n",
            "  eval_features_file: /content/gdrive/MyDrive/MT/src_val.txt\n",
            "  eval_labels_file: /content/gdrive/MyDrive/MT/tgt_infer.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "INFO:tensorflow:Using parameters:\n",
            "data:\n",
            "  eval_features_file: /content/gdrive/MyDrive/MT/src_val.txt\n",
            "  eval_labels_file: /content/gdrive/MyDrive/MT/tgt_infer.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "2022-12-31 07:08:02.123094: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-12-31 07:08:02.291000: I inputter.py:316] Initialized source input layer:\n",
            "INFO:tensorflow:Initialized source input layer:\n",
            "2022-12-31 07:08:02.294000: I inputter.py:316]  - vocabulary size: 40001\n",
            "INFO:tensorflow: - vocabulary size: 40001\n",
            "2022-12-31 07:08:02.298000: I inputter.py:316]  - special tokens: BOS=no, EOS=no\n",
            "INFO:tensorflow: - special tokens: BOS=no, EOS=no\n",
            "2022-12-31 07:08:03.828000: I inputter.py:316] Initialized target input layer:\n",
            "INFO:tensorflow:Initialized target input layer:\n",
            "2022-12-31 07:08:03.828000: I inputter.py:316]  - vocabulary size: 40001\n",
            "INFO:tensorflow: - vocabulary size: 40001\n",
            "2022-12-31 07:08:03.828000: I inputter.py:316]  - special tokens: BOS=yes, EOS=yes\n",
            "INFO:tensorflow: - special tokens: BOS=yes, EOS=yes\n",
            "2022-12-31 07:08:06.720000: I runner.py:442] Restored checkpoint /content/gdrive/MyDrive/MT/ckpt-33000\n",
            "INFO:tensorflow:Restored checkpoint /content/gdrive/MyDrive/MT/ckpt-33000\n",
            "2022-12-31 07:08:08.589000: I runner.py:451] Tracing and optimizing the inference graph...\n",
            "INFO:tensorflow:Tracing and optimizing the inference graph...\n"
          ]
        }
      ],
      "source": [
        "!onmt-main --config ./data.yaml --auto_config infer --features_file /content/gdrive/MyDrive/MT/src.txt --predictions_file out_infer.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sufS3OrguMHR"
      },
      "source": [
        "#Exporting the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt-main  --config ./data.yaml --auto_config infer --features_file src.txt --predictions_file tgt1_infer.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqb3VZ0CDXVK",
        "outputId": "e84909e0-32ec-41e8-da39-31827ef0361c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-28 04:03:21.359000: I main.py:302] Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "INFO:tensorflow:Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "2022-12-28 04:03:21.472000: I main.py:309] Using OpenNMT-tf version 2.30.0\n",
            "INFO:tensorflow:Using OpenNMT-tf version 2.30.0\n",
            "2022-12-28 04:03:21.472000: I main.py:309] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "INFO:tensorflow:Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2022-12-28 04:03:21.503000: I main.py:333] Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "INFO:tensorflow:Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-main\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/bin/main.py\", line 333, in main\n",
            "    runner.infer(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 440, in infer\n",
            "    model = self._init_model(config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 162, in _init_model\n",
            "    model.initialize(config[\"data\"], params=config[\"params\"])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/sequence_to_sequence.py\", line 124, in initialize\n",
            "    super().initialize(data_config, params=params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/model.py\", line 69, in initialize\n",
            "    self.examples_inputter.initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 913, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 316, in initialize\n",
            "    inputter.initialize(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 429, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 259, in initialize\n",
            "    ) = vocab.create_lookup_tables(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 259, in create_lookup_tables\n",
            "    vocabulary = Vocab.from_file(vocabulary_path)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 58, in from_file\n",
            "    vocab.load(path, file_format=file_format)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 121, in load\n",
            "    for i, line in enumerate(vocab):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 203, in __next__\n",
            "    retval = self.readline()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 167, in readline\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 76, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/gdrive/MyDrive/MT/vocab.src; No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt-main --config ./data.yaml --auto_config infer --features_file inf.txt --predictions_file src.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbhb_SbT_PFM",
        "outputId": "e9a5a5a8-83e7-479d-b49b-77776a94509f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-28 04:05:04.194000: I main.py:302] Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "INFO:tensorflow:Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "2022-12-28 04:05:04.309000: I main.py:309] Using OpenNMT-tf version 2.30.0\n",
            "INFO:tensorflow:Using OpenNMT-tf version 2.30.0\n",
            "2022-12-28 04:05:04.309000: I main.py:309] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "INFO:tensorflow:Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2022-12-28 04:05:04.358000: I main.py:333] Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "INFO:tensorflow:Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-main\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/bin/main.py\", line 333, in main\n",
            "    runner.infer(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 440, in infer\n",
            "    model = self._init_model(config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 162, in _init_model\n",
            "    model.initialize(config[\"data\"], params=config[\"params\"])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/sequence_to_sequence.py\", line 124, in initialize\n",
            "    super().initialize(data_config, params=params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/model.py\", line 69, in initialize\n",
            "    self.examples_inputter.initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 913, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 316, in initialize\n",
            "    inputter.initialize(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 429, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 259, in initialize\n",
            "    ) = vocab.create_lookup_tables(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 259, in create_lookup_tables\n",
            "    vocabulary = Vocab.from_file(vocabulary_path)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 58, in from_file\n",
            "    vocab.load(path, file_format=file_format)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 121, in load\n",
            "    for i, line in enumerate(vocab):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 203, in __next__\n",
            "    retval = self.readline()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 167, in readline\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 76, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/gdrive/MyDrive/MT/vocab.src; No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acTGgHQ0lVNR",
        "outputId": "0d93af23-1a90-458d-8c6d-5197bedf6776"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-28 04:05:47.801000: I main.py:302] Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "INFO:tensorflow:Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "2022-12-28 04:05:47.920000: I main.py:309] Using OpenNMT-tf version 2.30.0\n",
            "INFO:tensorflow:Using OpenNMT-tf version 2.30.0\n",
            "2022-12-28 04:05:47.920000: I main.py:309] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "INFO:tensorflow:Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2022-12-28 04:05:47.982000: I main.py:340] Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "INFO:tensorflow:Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-main\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/bin/main.py\", line 340, in main\n",
            "    runner.export(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 469, in export\n",
            "    model = self._init_model(config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 162, in _init_model\n",
            "    model.initialize(config[\"data\"], params=config[\"params\"])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/sequence_to_sequence.py\", line 124, in initialize\n",
            "    super().initialize(data_config, params=params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/model.py\", line 69, in initialize\n",
            "    self.examples_inputter.initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 913, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 316, in initialize\n",
            "    inputter.initialize(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 429, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 259, in initialize\n",
            "    ) = vocab.create_lookup_tables(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 259, in create_lookup_tables\n",
            "    vocabulary = Vocab.from_file(vocabulary_path)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 58, in from_file\n",
            "    vocab.load(path, file_format=file_format)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 121, in load\n",
            "    for i, line in enumerate(vocab):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 203, in __next__\n",
            "    retval = self.readline()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 167, in readline\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 76, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/gdrive/MyDrive/MT/vocab.src; No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!onmt-main --config data.yaml --auto_config export --output_dir /content/gdrive/MyDrive/MyDrive/V2/Models/  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt-main --config ./data.yaml --auto_config infer --features_file \"im giving a presentation in IITDWD\" --predictions_file tgt1_infer.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DGwgoAk6MiY",
        "outputId": "e8a24cca-3013-4e6e-b493-8a4434cabd49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-28 04:07:26.103000: I main.py:302] Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "INFO:tensorflow:Loading model description from /content/gdrive/MyDrive/MT/model_description.py\n",
            "2022-12-28 04:07:26.238000: I main.py:309] Using OpenNMT-tf version 2.30.0\n",
            "INFO:tensorflow:Using OpenNMT-tf version 2.30.0\n",
            "2022-12-28 04:07:26.238000: I main.py:309] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "INFO:tensorflow:Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2022-12-28 04:07:26.299000: I main.py:333] Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "INFO:tensorflow:Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-main\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/bin/main.py\", line 333, in main\n",
            "    runner.infer(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 440, in infer\n",
            "    model = self._init_model(config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 162, in _init_model\n",
            "    model.initialize(config[\"data\"], params=config[\"params\"])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/sequence_to_sequence.py\", line 124, in initialize\n",
            "    super().initialize(data_config, params=params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/model.py\", line 69, in initialize\n",
            "    self.examples_inputter.initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 913, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 316, in initialize\n",
            "    inputter.initialize(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 429, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 259, in initialize\n",
            "    ) = vocab.create_lookup_tables(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 259, in create_lookup_tables\n",
            "    vocabulary = Vocab.from_file(vocabulary_path)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 58, in from_file\n",
            "    vocab.load(path, file_format=file_format)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 121, in load\n",
            "    for i, line in enumerate(vocab):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 203, in __next__\n",
            "    retval = self.readline()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 167, in readline\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 76, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/gdrive/MyDrive/MT/vocab.src; No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sentence\n"
      ],
      "metadata": {
        "id": "5yweSn9i1nX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt-main --model_type Transformer --config data.yaml --auto_config infer --features_file /content/gdrive/MyDrive/MT/src.txt"
      ],
      "metadata": {
        "id": "1IKE7B_g34sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcfd9e7b-bec9-4ecd-a0df-31a9456babae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-28 03:36:33.926000: I onmt-main:8] Creating model directory /content/gdrive/MyDrive/MT\n",
            "INFO:tensorflow:Creating model directory /content/gdrive/MyDrive/MT\n",
            "2022-12-28 03:36:34.046000: I main.py:309] Using OpenNMT-tf version 2.30.0\n",
            "INFO:tensorflow:Using OpenNMT-tf version 2.30.0\n",
            "2022-12-28 03:36:34.047000: I main.py:309] Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "INFO:tensorflow:Using model:\n",
            "(model): TransformerBase(\n",
            "  (examples_inputter): SequenceToSequenceInputter(\n",
            "    (features_inputter): WordEmbedder()\n",
            "    (labels_inputter): WordEmbedder()\n",
            "    (inputters): ListWrapper(\n",
            "      (0): WordEmbedder()\n",
            "      (1): WordEmbedder()\n",
            "    )\n",
            "  )\n",
            "  (encoder): SelfAttentionEncoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionEncoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): SelfAttentionDecoder(\n",
            "    (position_encoder): SinusoidalPositionEncoder(\n",
            "      (reducer): SumReducer()\n",
            "    )\n",
            "    (layer_norm): LayerNorm()\n",
            "    (layers): ListWrapper(\n",
            "      (0): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (1): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (2): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (3): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (4): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "      (5): SelfAttentionDecoderLayer(\n",
            "        (self_attention): TransformerLayerWrapper(\n",
            "          (layer): MultiHeadAttention(\n",
            "            (linear_queries): Dense(512)\n",
            "            (linear_keys): Dense(512)\n",
            "            (linear_values): Dense(512)\n",
            "            (linear_output): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "        (attention): ListWrapper(\n",
            "          (0): TransformerLayerWrapper(\n",
            "            (layer): MultiHeadAttention(\n",
            "              (linear_queries): Dense(512)\n",
            "              (linear_keys): Dense(512)\n",
            "              (linear_values): Dense(512)\n",
            "              (linear_output): Dense(512)\n",
            "            )\n",
            "            (input_layer_norm): LayerNorm()\n",
            "          )\n",
            "        )\n",
            "        (ffn): TransformerLayerWrapper(\n",
            "          (layer): FeedForwardNetwork(\n",
            "            (inner): Dense(2048)\n",
            "            (outer): Dense(512)\n",
            "          )\n",
            "          (input_layer_norm): LayerNorm()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\n",
            "2022-12-28 03:36:34.125000: I main.py:333] Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "INFO:tensorflow:Using parameters:\n",
            "data:\n",
            "  eval_features_file: ./src_val.txt\n",
            "  eval_labels_file: ./tgt_val.txt\n",
            "  source_vocabulary: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  target_vocabulary: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "  train_features_file: /content/gdrive/MyDrive/MT/vocab.src\n",
            "  train_labels_file: /content/gdrive/MyDrive/MT/vocab.tgt\n",
            "eval:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  external_evaluators: BLEU\n",
            "  length_bucket_width: 5\n",
            "infer:\n",
            "  batch_size: 32\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "model_dir: /content/gdrive/MyDrive/MT\n",
            "params:\n",
            "  average_loss_in_time: true\n",
            "  beam_width: 4\n",
            "  decay_params:\n",
            "    model_dim: 512\n",
            "    warmup_steps: 8000\n",
            "  decay_type: NoamDecay\n",
            "  dropout: 0.3\n",
            "  label_smoothing: 0.1\n",
            "  learning_rate: 3.0\n",
            "  num_hypotheses: 1\n",
            "  optimizer: Adam\n",
            "  optimizer_params:\n",
            "    beta_1: 0.8\n",
            "    beta_2: 0.998\n",
            "score:\n",
            "  batch_size: 64\n",
            "  batch_type: examples\n",
            "  length_bucket_width: 5\n",
            "train:\n",
            "  average_last_checkpoints: 8\n",
            "  batch_size: 3072\n",
            "  batch_type: tokens\n",
            "  effective_batch_size: 25000\n",
            "  keep_checkpoint_max: 8\n",
            "  length_bucket_width: 2\n",
            "  max_step: 500000\n",
            "  maximum_features_length: 50\n",
            "  maximum_labels_length: 50\n",
            "  sample_buffer_size: -1\n",
            "  save_checkpoints_steps: 1000\n",
            "  save_summary_steps: 100\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt-main\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/bin/main.py\", line 333, in main\n",
            "    runner.infer(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 440, in infer\n",
            "    model = self._init_model(config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/runner.py\", line 162, in _init_model\n",
            "    model.initialize(config[\"data\"], params=config[\"params\"])\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/sequence_to_sequence.py\", line 124, in initialize\n",
            "    super().initialize(data_config, params=params)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/models/model.py\", line 69, in initialize\n",
            "    self.examples_inputter.initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 913, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/inputter.py\", line 316, in initialize\n",
            "    inputter.initialize(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 429, in initialize\n",
            "    super().initialize(data_config)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/inputters/text_inputter.py\", line 259, in initialize\n",
            "    ) = vocab.create_lookup_tables(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 259, in create_lookup_tables\n",
            "    vocabulary = Vocab.from_file(vocabulary_path)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 58, in from_file\n",
            "    vocab.load(path, file_format=file_format)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/opennmt/data/vocab.py\", line 121, in load\n",
            "    for i, line in enumerate(vocab):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 203, in __next__\n",
            "    retval = self.readline()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 167, in readline\n",
            "    self._preread_check()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/lib/io/file_io.py\", line 76, in _preread_check\n",
            "    self._read_buf = _pywrap_file_io.BufferedInputStream(\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /content/gdrive/MyDrive/MT/vocab.src; No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt-main --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12wp3-yL5oC4",
        "outputId": "21252a2c-23a8-47f9-a680-169e897a179b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: onmt-main\n",
            "       [-h]\n",
            "       [-v]\n",
            "       --config\n",
            "       CONFIG\n",
            "       [CONFIG ...]\n",
            "       [--model_dir MODEL_DIR]\n",
            "       [--auto_config]\n",
            "       [--model_type {GPT2Small,ListenAttendSpell,LstmCnnCrfTagger,LuongAttention,NMTBigV1,NMTMediumV1,NMTSmallV1,ScalingNmtEnDe,ScalingNmtEnFr,Transformer,TransformerBase,TransformerBaseRelative,TransformerBaseSharedEmbeddings,TransformerBig,TransformerBigRelative,TransformerBigSharedEmbeddings,TransformerRelative,TransformerTiny}]\n",
            "       [--model MODEL]\n",
            "       [--run_dir RUN_DIR]\n",
            "       [--data_dir DATA_DIR]\n",
            "       [--checkpoint_path CHECKPOINT_PATH]\n",
            "       [--log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}]\n",
            "       [--seed SEED]\n",
            "       [--gpu_allow_growth]\n",
            "       [--intra_op_parallelism_threads INTRA_OP_PARALLELISM_THREADS]\n",
            "       [--inter_op_parallelism_threads INTER_OP_PARALLELISM_THREADS]\n",
            "       [--mixed_precision]\n",
            "       [--eager_execution]\n",
            "       {train,eval,infer,export,score,average_checkpoints,update_vocab}\n",
            "       ...\n",
            "\n",
            "positional arguments:\n",
            "  {train,eval,infer,export,score,average_checkpoints,update_vocab}\n",
            "    Run type.\n",
            "    train\n",
            "    Training.\n",
            "    eval\n",
            "    Evaluation.\n",
            "    infer\n",
            "    Inference.\n",
            "    export\n",
            "    Model\n",
            "    export.\n",
            "    score\n",
            "    Scoring.\n",
            "    average_checkpoints\n",
            "    Checkpoint\n",
            "    averaging.\n",
            "    update_vocab\n",
            "    Update\n",
            "    model vocab\n",
            "    ularies in\n",
            "    checkpoint.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  -v, --version\n",
            "    show\n",
            "    program's\n",
            "    version\n",
            "    number and\n",
            "    exit\n",
            "  --config CONFIG [CONFIG ...]\n",
            "    List of con\n",
            "    figuration\n",
            "    files.\n",
            "    (default:\n",
            "    None)\n",
            "  --model_dir MODEL_DIR\n",
            "    Path to the\n",
            "    model\n",
            "    directory.\n",
            "    If not set,\n",
            "    the model\n",
            "    directory\n",
            "    is read\n",
            "    from the\n",
            "    field\n",
            "    'model_dir'\n",
            "    in the conf\n",
            "    iguration.\n",
            "    (default:\n",
            "    None)\n",
            "  --auto_config\n",
            "    Enable\n",
            "    automatic c\n",
            "    onfiguratio\n",
            "    n values.\n",
            "    (default:\n",
            "    None)\n",
            "  --model_type {GPT2Small,ListenAttendSpell,LstmCnnCrfTagger,LuongAttention,NMTBigV1,NMTMediumV1,NMTSmallV1,ScalingNmtEnDe,ScalingNmtEnFr,Transformer,TransformerBase,TransformerBaseRelative,TransformerBaseSharedEmbeddings,TransformerBig,TransformerBigRelative,TransformerBigSharedEmbeddings,TransformerRelative,TransformerTiny}\n",
            "    Model type\n",
            "    from the\n",
            "    catalog.\n",
            "    (default: )\n",
            "  --model MODEL\n",
            "    Custom\n",
            "    model confi\n",
            "    guration\n",
            "    file.\n",
            "    (default: )\n",
            "  --run_dir RUN_DIR\n",
            "    If set,\n",
            "    model_dir\n",
            "    will be\n",
            "    created\n",
            "    relative to\n",
            "    this\n",
            "    location.\n",
            "    (default: )\n",
            "  --data_dir DATA_DIR\n",
            "    If set,\n",
            "    data files\n",
            "    are\n",
            "    expected to\n",
            "    be relative\n",
            "    to this\n",
            "    location.\n",
            "    (default: )\n",
            "  --checkpoint_path CHECKPOINT_PATH\n",
            "    Path to the\n",
            "    checkpoint\n",
            "    or\n",
            "    checkpoint\n",
            "    directory\n",
            "    to load. If\n",
            "    not set,\n",
            "    the latest\n",
            "    checkpoint\n",
            "    from the\n",
            "    model\n",
            "    directory\n",
            "    is loaded.\n",
            "    (default:\n",
            "    None)\n",
            "  --log_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET}\n",
            "    Logs\n",
            "    verbosity.\n",
            "    (default:\n",
            "    INFO)\n",
            "  --seed SEED\n",
            "    Random\n",
            "    seed.\n",
            "    (default:\n",
            "    None)\n",
            "  --gpu_allow_growth\n",
            "    Allocate\n",
            "    GPU memory \n",
            "    dynamically\n",
            "    . (default:\n",
            "    False)\n",
            "  --intra_op_parallelism_threads INTRA_OP_PARALLELISM_THREADS\n",
            "    Number of\n",
            "    intra op\n",
            "    threads (0\n",
            "    means the\n",
            "    system\n",
            "    picks an\n",
            "    appropriate\n",
            "    number).\n",
            "    (default:\n",
            "    0)\n",
            "  --inter_op_parallelism_threads INTER_OP_PARALLELISM_THREADS\n",
            "    Number of\n",
            "    inter op\n",
            "    threads (0\n",
            "    means the\n",
            "    system\n",
            "    picks an\n",
            "    appropriate\n",
            "    number).\n",
            "    (default:\n",
            "    0)\n",
            "  --mixed_precision\n",
            "    Enable\n",
            "    mixed\n",
            "    precision.\n",
            "    (default:\n",
            "    False)\n",
            "  --eager_execution\n",
            "    Enable\n",
            "    TensorFlow\n",
            "    eager\n",
            "    execution.\n",
            "    (default:\n",
            "    False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1euWHE-GnQKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e077d559-84bd-4810-8122-8a7e5c196c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.97)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 180, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 199, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 385, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/commands/install.py\", line 515, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/check.py\", line 103, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/operations/check.py\", line 45, in create_package_set_from_installed\n",
            "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3033, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3094, in parse_requirements\n",
            "    yield Requirement(line)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3101, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/packaging/requirements.py\", line 113, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1943, in parseString\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
            "    ret = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4849, in parseImpl\n",
            "    loc, tokens = self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4462, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4781, in parseImpl\n",
            "    return super(ZeroOrMore, self).parseImpl(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4697, in parseImpl\n",
            "    loc, tokens = self_expr_parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4069, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4462, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4052, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
            "    ret = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4462, in parseImpl\n",
            "    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4052, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
            "    ret = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1683, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, preloc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 4254, in parseImpl\n",
            "    ret = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/pyparsing.py\", line 1647, in _parseNoCache\n",
            "    def _parseNoCache(self, instring, loc, doActions=True, callPreParse=True):\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1697, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 71, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 104, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 212, in _main\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1492, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1705, in isEnabledFor\n",
            "    level >= self.getEffectiveLevel()\n",
            "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1675, in getEffectiveLevel\n",
            "    def getEffectiveLevel(self):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o5aoMMuqUNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e541f6-adc4-438d-958d-51fafff300e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu2).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libunwind-dev\n",
            "The following NEW packages will be installed:\n",
            "  libgoogle-perftools-dev libunwind-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 627 kB of archives.\n",
            "After this operation, 6,761 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libunwind-dev amd64 1.2.1-8 [423 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgoogle-perftools-dev amd64 2.5-2.2ubuntu3 [204 kB]\n",
            "Fetched 627 kB in 1s (534 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libunwind-dev:amd64.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../libunwind-dev_1.2.1-8_amd64.deb ...\n",
            "Unpacking libunwind-dev:amd64 (1.2.1-8) ...\n",
            "Selecting previously unselected package libgoogle-perftools-dev.\n",
            "Preparing to unpack .../libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb ...\n",
            "Unpacking libgoogle-perftools-dev (2.5-2.2ubuntu3) ...\n",
            "Setting up libunwind-dev:amd64 (1.2.1-8) ...\n",
            "Setting up libgoogle-perftools-dev (2.5-2.2ubuntu3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install cmake build-essential pkg-config libgoogle-perftools-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-tErAr1j3y-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e49779-af6d-44a1-f701-15cbaeb72b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- VERSION: 0.1.97\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Found TCMalloc: /usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/sentencepiece/build\n",
            "[  0%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/arena.cc.o\n",
            "[  1%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arena.cc.o\n",
            "[  2%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/arenastring.cc.o\n",
            "[  3%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/arenastring.cc.o\n",
            "[  4%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/bytestream.cc.o\n",
            "[  5%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/bytestream.cc.o\n",
            "[  6%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/coded_stream.cc.o\n",
            "[  7%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/coded_stream.cc.o\n",
            "[  8%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/common.cc.o\n",
            "[  9%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/common.cc.o\n",
            "[ 10%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/extension_set.cc.o\n",
            "[ 11%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/extension_set.cc.o\n",
            "[ 12%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_enum_util.cc.o\n",
            "[ 13%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_enum_util.cc.o\n",
            "[ 13%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\n",
            "[ 14%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_message_table_driven_lite.cc.o\n",
            "[ 15%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\n",
            "[ 15%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/generated_message_util.cc.o\n",
            "[ 16%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\n",
            "[ 17%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/implicit_weak_message.cc.o\n",
            "[ 18%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/int128.cc.o\n",
            "[ 19%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/int128.cc.o\n",
            "[ 20%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/io_win32.cc.o\n",
            "[ 21%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/message_lite.cc.o\n",
            "[ 22%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/io_win32.cc.o\n",
            "[ 23%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/message_lite.cc.o\n",
            "[ 24%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/parse_context.cc.o\n",
            "[ 25%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/parse_context.cc.o\n",
            "[ 26%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/repeated_field.cc.o\n",
            "[ 27%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/repeated_field.cc.o\n",
            "[ 28%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/status.cc.o\n",
            "[ 29%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/status.cc.o\n",
            "[ 29%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/statusor.cc.o\n",
            "[ 29%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/statusor.cc.o\n",
            "[ 30%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringpiece.cc.o\n",
            "[ 31%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/stringpiece.cc.o\n",
            "[ 32%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/stringprintf.cc.o\n",
            "[ 33%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/stringprintf.cc.o\n",
            "[ 34%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\n",
            "[ 35%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/structurally_valid.cc.o\n",
            "[ 36%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/strutil.cc.o\n",
            "[ 37%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/strutil.cc.o\n",
            "[ 38%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/time.cc.o\n",
            "[ 39%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/time.cc.o\n",
            "[ 40%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\n",
            "[ 41%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/wire_format_lite.cc.o\n",
            "[ 42%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\n",
            "[ 43%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream.cc.o\n",
            "[ 43%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl.cc.o\n",
            "[ 43%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream_impl.cc.o\n",
            "[ 44%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\n",
            "[ 45%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/protobuf-lite/zero_copy_stream_impl_lite.cc.o\n",
            "[ 46%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece.pb.cc.o\n",
            "[ 47%] Building CXX object src/CMakeFiles/sentencepiece.dir/builtin_pb/sentencepiece.pb.cc.o\n",
            "[ 48%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/builtin_pb/sentencepiece_model.pb.cc.o\n",
            "[ 49%] Building CXX object src/CMakeFiles/sentencepiece.dir/builtin_pb/sentencepiece_model.pb.cc.o\n",
            "[ 50%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/bpe_model.cc.o\n",
            "[ 51%] Building CXX object src/CMakeFiles/sentencepiece.dir/bpe_model.cc.o\n",
            "[ 52%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/char_model.cc.o\n",
            "[ 53%] Building CXX object src/CMakeFiles/sentencepiece.dir/char_model.cc.o\n",
            "[ 54%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/error.cc.o\n",
            "[ 55%] Building CXX object src/CMakeFiles/sentencepiece.dir/error.cc.o\n",
            "[ 56%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/filesystem.cc.o\n",
            "[ 57%] Building CXX object src/CMakeFiles/sentencepiece.dir/filesystem.cc.o\n",
            "[ 57%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/model_factory.cc.o\n",
            "[ 57%] Building CXX object src/CMakeFiles/sentencepiece.dir/model_factory.cc.o\n",
            "[ 58%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/model_interface.cc.o\n",
            "[ 59%] Building CXX object src/CMakeFiles/sentencepiece.dir/model_interface.cc.o\n",
            "[ 60%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/normalizer.cc.o\n",
            "[ 61%] Building CXX object src/CMakeFiles/sentencepiece.dir/normalizer.cc.o\n",
            "[ 62%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/sentencepiece_processor.cc.o\n",
            "[ 63%] Building CXX object src/CMakeFiles/sentencepiece.dir/sentencepiece_processor.cc.o\n",
            "[ 64%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/unigram_model.cc.o\n",
            "[ 65%] Building CXX object src/CMakeFiles/sentencepiece.dir/unigram_model.cc.o\n",
            "[ 66%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/util.cc.o\n",
            "[ 67%] Building CXX object src/CMakeFiles/sentencepiece.dir/util.cc.o\n",
            "[ 68%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/word_model.cc.o\n",
            "[ 69%] Building CXX object src/CMakeFiles/sentencepiece.dir/word_model.cc.o\n",
            "[ 70%] Building CXX object src/CMakeFiles/sentencepiece-static.dir/__/third_party/absl/flags/flag.cc.o\n",
            "[ 71%] Building CXX object src/CMakeFiles/sentencepiece.dir/__/third_party/absl/flags/flag.cc.o\n",
            "[ 71%] Linking CXX static library libsentencepiece.a\n",
            "[ 71%] Built target sentencepiece-static\n",
            "[ 72%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/builder.cc.o\n",
            "[ 72%] Linking CXX shared library libsentencepiece.so\n",
            "[ 72%] Built target sentencepiece\n",
            "[ 73%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/builder.cc.o\n",
            "[ 74%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/unicode_script.cc.o\n",
            "[ 75%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/unicode_script.cc.o\n",
            "[ 76%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_factory.cc.o\n",
            "[ 77%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/trainer_factory.cc.o\n",
            "[ 78%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/trainer_interface.cc.o\n",
            "[ 79%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/trainer_interface.cc.o\n",
            "[ 79%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/unigram_model_trainer.cc.o\n",
            "[ 80%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/unigram_model_trainer.cc.o\n",
            "[ 81%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/word_model_trainer.cc.o\n",
            "[ 82%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/word_model_trainer.cc.o\n",
            "[ 83%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/char_model_trainer.cc.o\n",
            "[ 84%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/char_model_trainer.cc.o\n",
            "[ 84%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/bpe_model_trainer.cc.o\n",
            "[ 85%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/bpe_model_trainer.cc.o\n",
            "[ 86%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/sentencepiece_trainer.cc.o\n",
            "[ 87%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/sentencepiece_trainer.cc.o\n",
            "[ 88%] Building CXX object src/CMakeFiles/sentencepiece_train-static.dir/pretokenizer_for_training.cc.o\n",
            "[ 89%] Building CXX object src/CMakeFiles/sentencepiece_train.dir/pretokenizer_for_training.cc.o\n",
            "[ 90%] Linking CXX static library libsentencepiece_train.a\n",
            "[ 90%] Built target sentencepiece_train-static\n",
            "[ 91%] Building CXX object src/CMakeFiles/spm_encode.dir/spm_encode_main.cc.o\n",
            "[ 92%] Linking CXX shared library libsentencepiece_train.so\n",
            "[ 92%] Built target sentencepiece_train\n",
            "[ 93%] Building CXX object src/CMakeFiles/spm_decode.dir/spm_decode_main.cc.o\n",
            "[ 93%] Linking CXX executable spm_decode\n",
            "[ 93%] Built target spm_decode\n",
            "[ 94%] Building CXX object src/CMakeFiles/spm_normalize.dir/spm_normalize_main.cc.o\n",
            "[ 95%] Linking CXX executable spm_encode\n",
            "[ 95%] Built target spm_encode\n",
            "[ 96%] Building CXX object src/CMakeFiles/spm_train.dir/spm_train_main.cc.o\n",
            "[ 97%] Linking CXX executable spm_normalize\n",
            "[ 97%] Built target spm_normalize\n",
            "[ 98%] Building CXX object src/CMakeFiles/spm_export_vocab.dir/spm_export_vocab_main.cc.o\n",
            "[ 99%] Linking CXX executable spm_train\n",
            "[ 99%] Built target spm_train\n",
            "[100%] Linking CXX executable spm_export_vocab\n",
            "[100%] Built target spm_export_vocab\n",
            "Consolidate compiler generated dependencies of target sentencepiece\n",
            "[ 35%] Built target sentencepiece\n",
            "Consolidate compiler generated dependencies of target sentencepiece_train\n",
            "[ 45%] Built target sentencepiece_train\n",
            "Consolidate compiler generated dependencies of target sentencepiece-static\n",
            "[ 81%] Built target sentencepiece-static\n",
            "Consolidate compiler generated dependencies of target sentencepiece_train-static\n",
            "[ 91%] Built target sentencepiece_train-static\n",
            "Consolidate compiler generated dependencies of target spm_encode\n",
            "[ 93%] Built target spm_encode\n",
            "Consolidate compiler generated dependencies of target spm_decode\n",
            "[ 94%] Built target spm_decode\n",
            "Consolidate compiler generated dependencies of target spm_normalize\n",
            "[ 96%] Built target spm_normalize\n",
            "Consolidate compiler generated dependencies of target spm_train\n",
            "[ 98%] Built target spm_train\n",
            "Consolidate compiler generated dependencies of target spm_export_vocab\n",
            "[100%] Built target spm_export_vocab\n",
            "Install the project...\n",
            "-- Install configuration: \"\"\n",
            "-- Installing: /usr/local/lib/pkgconfig/sentencepiece.pc\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so.0.0.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece.so\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so.0.0.0\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so.0\n",
            "-- Set runtime path of \"/usr/local/lib/libsentencepiece_train.so.0.0.0\" to \"\"\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.so\n",
            "-- Installing: /usr/local/lib/libsentencepiece.a\n",
            "-- Installing: /usr/local/lib/libsentencepiece_train.a\n",
            "-- Installing: /usr/local/bin/spm_encode\n",
            "-- Set runtime path of \"/usr/local/bin/spm_encode\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_decode\n",
            "-- Set runtime path of \"/usr/local/bin/spm_decode\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_normalize\n",
            "-- Set runtime path of \"/usr/local/bin/spm_normalize\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_train\n",
            "-- Set runtime path of \"/usr/local/bin/spm_train\" to \"\"\n",
            "-- Installing: /usr/local/bin/spm_export_vocab\n",
            "-- Set runtime path of \"/usr/local/bin/spm_export_vocab\" to \"\"\n",
            "-- Installing: /usr/local/include/sentencepiece_trainer.h\n",
            "-- Installing: /usr/local/include/sentencepiece_processor.h\n",
            "/usr/local/cuda/targets/x86_64-linux/lib:\n",
            "\tlibnvjpeg.so.11 -> libnvjpeg.so.11.4.0.152\n",
            "\tlibcusolver.so.11 -> libcusolver.so.11.1.0.152\n",
            "\tlibnppif.so.11 -> libnppif.so.11.3.2.152\n",
            "\tlibcufftw.so.10 -> libcufftw.so.10.4.1.152\n",
            "\tlibnvrtc.so.11.2 -> libnvrtc.so.11.2.152\n",
            "\tlibcurand.so.10 -> libcurand.so.10.2.3.152\n",
            "\tlibnppisu.so.11 -> libnppisu.so.11.3.2.152\n",
            "\tlibcusparse.so.11 -> libcusparse.so.11.4.1.1152\n",
            "\tlibcufft.so.10 -> libcufft.so.10.4.1.152\n",
            "\tlibnppist.so.11 -> libnppist.so.11.3.2.152\n",
            "\tlibnppial.so.11 -> libnppial.so.11.3.2.152\n",
            "\tlibnppc.so.11 -> libnppc.so.11.3.2.152\n",
            "\tlibnppidei.so.11 -> libnppidei.so.11.3.2.152\n",
            "\tlibnvrtc-builtins.so.11.2 -> libnvrtc-builtins.so.11.2.152\n",
            "\tlibcublasLt.so.11 -> libcublasLt.so.11.4.1.1043\n",
            "\tlibcublas.so.11 -> libcublas.so.11.4.1.1043\n",
            "\tlibnppicc.so.11 -> libnppicc.so.11.3.2.152\n",
            "\tlibnpps.so.11 -> libnpps.so.11.3.2.152\n",
            "\tlibnvblas.so.11 -> libnvblas.so.11.4.1.1043\n",
            "\tlibnppitc.so.11 -> libnppitc.so.11.3.2.152\n",
            "\tlibnppim.so.11 -> libnppim.so.11.3.2.152\n",
            "\tlibcusolverMg.so.11 -> libcusolverMg.so.11.1.0.152\n",
            "\tlibnppig.so.11 -> libnppig.so.11.3.2.152\n",
            "\tlibnvToolsExt.so.1 -> libnvToolsExt.so.1.0.0\n",
            "\tlibcupti.so.11.2 -> libcupti.so.2020.3.1\n",
            "\tlibnvperf_host.so -> libnvperf_host.so\n",
            "\tlibaccinj64.so.11.2 -> libaccinj64.so.11.2.152\n",
            "\tlibnvperf_target.so -> libnvperf_target.so\n",
            "\tlibcuinj64.so.11.2 -> libcuinj64.so.11.2.152\n",
            "\tlibOpenCL.so.1 -> libOpenCL.so.1.0.0\n",
            "\tlibcudart.so.11.0 -> libcudart.so.11.2.152\n",
            "/usr/local/lib:\n",
            "\tlibmkl_gf_ilp64.so -> libmkl_gf_ilp64.so\n",
            "\tlibmkl_blacs_openmpi_ilp64.so -> libmkl_blacs_openmpi_ilp64.so\n",
            "\tlibmkl_vml_avx.so -> libmkl_vml_avx.so\n",
            "\tlibmkl_avx512_mic.so -> libmkl_avx512_mic.so\n",
            "\tlibmkl_core.so -> libmkl_core.so\n",
            "\tlibmkl_gf_lp64.so -> libmkl_gf_lp64.so\n",
            "\tlibmkl_blacs_intelmpi_lp64.so -> libmkl_blacs_intelmpi_lp64.so\n",
            "\tlibmkl_vml_mc2.so -> libmkl_vml_mc2.so\n",
            "\tlibomptarget.so -> libomptarget.so\n",
            "\tlibmkl_mc.so -> libmkl_mc.so\n",
            "\tlibiompstubs5.so -> libiompstubs5.so\n",
            "\tlibmkl_rt.so -> libmkl_rt.so\n",
            "\tlibmkl_intel_thread.so -> libmkl_intel_thread.so\n",
            "\tlibomptarget.rtl.opencl.so -> libomptarget.rtl.opencl.so\n",
            "\tlibmkl_blacs_intelmpi_ilp64.so -> libmkl_blacs_intelmpi_ilp64.so\n",
            "\tlibmkl_mc3.so -> libmkl_mc3.so\n",
            "\tlibmkl_vml_avx512.so -> libmkl_vml_avx512.so\n",
            "\tlibmkl_avx512.so -> libmkl_avx512.so\n",
            "\tlibmkl_pgi_thread.so -> libmkl_pgi_thread.so\n",
            "\tlibmkl_avx2.so -> libmkl_avx2.so\n",
            "\tlibmkl_vml_cmpt.so -> libmkl_vml_cmpt.so\n",
            "\tlibmkl_def.so -> libmkl_def.so\n",
            "\tlibmkl_scalapack_ilp64.so -> libmkl_scalapack_ilp64.so\n",
            "\tlibmkl_gnu_thread.so -> libmkl_gnu_thread.so\n",
            "\tlibmkl_vml_mc.so -> libmkl_vml_mc.so\n",
            "\tlibiomp5_db.so -> libiomp5_db.so\n",
            "\tlibomptarget.sycl.wrap.so -> libomptarget.sycl.wrap.so\n",
            "\tlibmkl_vml_mc3.so -> libmkl_vml_mc3.so\n",
            "\tlibmkl_blacs_sgimpt_lp64.so -> libmkl_blacs_sgimpt_lp64.so\n",
            "\tlibmkl_cdft_core.so -> libmkl_cdft_core.so\n",
            "\tlibmkl_vml_avx2.so -> libmkl_vml_avx2.so\n",
            "\tlibmkl_intel_ilp64.so -> libmkl_intel_ilp64.so\n",
            "\tlibmkl_vml_def.so -> libmkl_vml_def.so\n",
            "\tlibmkl_scalapack_lp64.so -> libmkl_scalapack_lp64.so\n",
            "\tlibiomp5.so -> libiomp5.so\n",
            "\tlibmkl_sequential.so -> libmkl_sequential.so\n",
            "\tlibomptarget.rtl.x86_64.so -> libomptarget.rtl.x86_64.so\n",
            "\tlibmkl_blacs_sgimpt_ilp64.so -> libmkl_blacs_sgimpt_ilp64.so\n",
            "\tlibomptarget.rtl.level0.so -> libomptarget.rtl.level0.so\n",
            "\tlibmkl_tbb_thread.so -> libmkl_tbb_thread.so\n",
            "\tlibmkl_intel_lp64.so -> libmkl_intel_lp64.so\n",
            "\tlibmkl_vml_avx512_mic.so -> libmkl_vml_avx512_mic.so\n",
            "\tlibmkl_blacs_openmpi_lp64.so -> libmkl_blacs_openmpi_lp64.so\n",
            "\tlibmkl_avx.so -> libmkl_avx.so\n",
            "\tlibsentencepiece_train.so.0 -> libsentencepiece_train.so.0.0.0\n",
            "\tlibsentencepiece.so.0 -> libsentencepiece.so.0.0.0\n",
            "/lib/x86_64-linux-gnu:\n",
            "\tlibreadline.so.7 -> libreadline.so.7.0\n",
            "\tlibhistory.so.7 -> libhistory.so.7.0\n",
            "\tlibjson-c.so.3 -> libjson-c.so.3.0.1\n",
            "\tlibaio.so.1 -> libaio.so.1.0.1\n",
            "\tlibapparmor.so.1 -> libapparmor.so.1.4.2\n",
            "\tlibdevmapper.so.1.02.1 -> libdevmapper.so.1.02.1\n",
            "\tlibbsd.so.0 -> libbsd.so.0.8.7\n",
            "\tlibidn.so.11 -> libidn.so.11.6.16\n",
            "\tlibnl-3.so.200 -> libnl-3.so.200.24.0\n",
            "\tlibmnl.so.0 -> libmnl.so.0.2.0\n",
            "\tlibulockmgr.so.1 -> libulockmgr.so.1.0.1\n",
            "\tlibexpat.so.1 -> libexpat.so.1.6.7\n",
            "\tlibkmod.so.2 -> libkmod.so.2.3.2\n",
            "\tlibslang.so.2 -> libslang.so.2.3.1\n",
            "\tlibkeyutils.so.1 -> libkeyutils.so.1.5\n",
            "\tlibdbus-1.so.3 -> libdbus-1.so.3.19.4\n",
            "\tliblzo2.so.2 -> liblzo2.so.2.0.0\n",
            "\tlibwrap.so.0 -> libwrap.so.0.7.6\n",
            "\tlibfuse.so.2 -> libfuse.so.2.9.7\n",
            "\tlibcryptsetup.so.12 -> libcryptsetup.so.12.2.0\n",
            "\tlibusb-1.0.so.0 -> libusb-1.0.so.0.1.0\n",
            "\tlibcap.so.2 -> libcap.so.2.25\n",
            "\tlibcap-ng.so.0 -> libcap-ng.so.0.0.0\n",
            "\tlibgcc_s.so.1 -> libgcc_s.so.1\n",
            "\tlibaudit.so.1 -> libaudit.so.1.0.0\n",
            "\tlibncurses.so.5 -> libncurses.so.5.9\n",
            "\tlibpam_misc.so.0 -> libpam_misc.so.0.82.0\n",
            "\tlibc.so.6 -> libc-2.27.so\n",
            "\tlibmemusage.so -> libmemusage.so\n",
            "\tlibcidn.so.1 -> libcidn-2.27.so\n",
            "\tlibnss_nis.so.2 -> libnss_nis-2.27.so\n",
            "\tlibss.so.2 -> libss.so.2.0\n",
            "\tlibblkid.so.1 -> libblkid.so.1.1.0\n",
            "\tlibnss_files.so.2 -> libnss_files-2.27.so\n",
            "\tlibsepol.so.1 -> libsepol.so.1\n",
            "\tlibext2fs.so.2 -> libext2fs.so.2.4\n",
            "\tlibnsl.so.1 -> libnsl-2.27.so\n",
            "\tlibgpg-error.so.0 -> libgpg-error.so.0.22.0\n",
            "\tlibz.so.1 -> libz.so.1.2.11\n",
            "\tlibcom_err.so.2 -> libcom_err.so.2.1\n",
            "\tlibanl.so.1 -> libanl-2.27.so\n",
            "\tlibselinux.so.1 -> libselinux.so.1\n",
            "\tlibpam.so.0 -> libpam.so.0.83.1\n",
            "\tlibattr.so.1 -> libattr.so.1.1.0\n",
            "\tlibSegFault.so -> libSegFault.so\n",
            "\tlibsystemd.so.0 -> libsystemd.so.0.21.0\n",
            "\tlibthread_db.so.1 -> libthread_db-1.0.so\n",
            "\tlibgcrypt.so.20 -> libgcrypt.so.20.2.1\n",
            "\tlibdl.so.2 -> libdl-2.27.so\n",
            "\tlibpamc.so.0 -> libpamc.so.0.82.1\n",
            "\tlibrt.so.1 -> librt-2.27.so\n",
            "\tlibmvec.so.1 -> libmvec-2.27.so\n",
            "\tlibutil.so.1 -> libutil-2.27.so\n",
            "\tlibncursesw.so.5 -> libncursesw.so.5.9\n",
            "\tlibacl.so.1 -> libacl.so.1.1.0\n",
            "\tlibpcprofile.so -> libpcprofile.so\n",
            "\tlibpthread.so.0 -> libpthread-2.27.so\n",
            "\tld-linux-x86-64.so.2 -> ld-2.27.so\n",
            "\tlibsmartcols.so.1 -> libsmartcols.so.1.1.0\n",
            "\tlibtinfo.so.5 -> libtinfo.so.5.9\n",
            "\tlibseccomp.so.2 -> libseccomp.so.2.5.1\n",
            "\tlibnss_dns.so.2 -> libnss_dns-2.27.so\n",
            "\tlibnss_hesiod.so.2 -> libnss_hesiod-2.27.so\n",
            "\tlibbz2.so.1.0 -> libbz2.so.1.0.4\n",
            "\tlibfdisk.so.1 -> libfdisk.so.1.1.0\n",
            "\tlibresolv.so.2 -> libresolv-2.27.so\n",
            "\tlibcrypt.so.1 -> libcrypt-2.27.so\n",
            "\tlibprocps.so.6 -> libprocps.so.6.0.0\n",
            "\tlibudev.so.1 -> libudev.so.1.6.9\n",
            "\tliblzma.so.5 -> liblzma.so.5.2.2\n",
            "\tlibmount.so.1 -> libmount.so.1.1.0\n",
            "\tlibnss_compat.so.2 -> libnss_compat-2.27.so\n",
            "\tlibuuid.so.1 -> libuuid.so.1.3.0\n",
            "\tlibBrokenLocale.so.1 -> libBrokenLocale-2.27.so\n",
            "\tlibnss_nisplus.so.2 -> libnss_nisplus-2.27.so\n",
            "\tlibe2p.so.2 -> libe2p.so.2.3\n",
            "\tlibpcre.so.3 -> libpcre.so.3.13.3\n",
            "\tlibm.so.6 -> libm-2.27.so\n",
            "/usr/lib/x86_64-linux-gnu:\n",
            "\tlibssl.so.1.1 -> libssl.so.1.1\n",
            "\tlibheimbase.so.1 -> libheimbase.so.1.0.0\n",
            "\tlibnpth.so.0 -> libnpth.so.0.1.1\n",
            "\tlibksba.so.8 -> libksba.so.8.11.6\n",
            "\tlibgssapi.so.3 -> libgssapi.so.3.0.0\n",
            "\tlibcrypto.so.1.1 -> libcrypto.so.1.1\n",
            "\tlibroken.so.18 -> libroken.so.18.1.0\n",
            "\tlibwind.so.0 -> libwind.so.0.0.0\n",
            "\tlibhx509.so.5 -> libhx509.so.5.0.0\n",
            "\tliblber-2.4.so.2 -> liblber-2.4.so.2.10.8\n",
            "\tlibhcrypto.so.4 -> libhcrypto.so.4.1.0\n",
            "\tlibassuan.so.0 -> libassuan.so.0.8.1\n",
            "\tlibldap_r-2.4.so.2 -> libldap_r-2.4.so.2.10.8\n",
            "\tlibkrb5.so.26 -> libkrb5.so.26.0.0\n",
            "\tlibsasl2.so.2 -> libsasl2.so.2.0.25\n",
            "\tlibasn1.so.8 -> libasn1.so.8.0.0\n",
            "\tlibheimntlm.so.0 -> libheimntlm.so.0.1.0\n",
            "\tlibnccl.so.2 -> libnccl.so.2.8.4\n",
            "\tlibbfd-2.30-system.so -> libbfd-2.30-system.so\n",
            "\tlibitm.so.1 -> libitm.so.1.0.0\n",
            "\tlibcc1.so.0 -> libcc1.so.0.0.0\n",
            "\tlibcilkrts.so.5 -> libcilkrts.so.5.0.0\n",
            "\tlibgdbm_compat.so.4 -> libgdbm_compat.so.4.0.0\n",
            "\tlibasan.so.4 -> libasan.so.4.0.0\n",
            "\tlibmpx.so.2 -> libmpx.so.2.0.1\n",
            "\tlibmpfr.so.6 -> libmpfr.so.6.0.1\n",
            "\tlibatomic.so.1 -> libatomic.so.1.2.0\n",
            "\tliblsan.so.0 -> liblsan.so.0.0.0\n",
            "\tlibubsan.so.0 -> libubsan.so.0.0.0\n",
            "\tlibquadmath.so.0 -> libquadmath.so.0.0.0\n",
            "\tlibmpc.so.3 -> libmpc.so.3.1.0\n",
            "\tlibisl.so.19 -> libisl.so.19.0.0\n",
            "\tlibtsan.so.0 -> libtsan.so.0.0.0\n",
            "\tlibmpxwrappers.so.2 -> libmpxwrappers.so.2.0.1\n",
            "\tlibgdbm.so.5 -> libgdbm.so.5.0.0\n",
            "\tlibopcodes-2.30-system.so -> libopcodes-2.30-system.so\n",
            "\tlibperl.so.5.26 -> libperl.so.5.26.1\n",
            "\tlibgomp.so.1 -> libgomp.so.1.0.0\n",
            "\tlibcudnn_adv_train.so.8 -> libcudnn_adv_train.so.8.1.1\n",
            "\tlibcudnn_adv_infer.so.8 -> libcudnn_adv_infer.so.8.1.1\n",
            "\tlibcudnn_ops_train.so.8 -> libcudnn_ops_train.so.8.1.1\n",
            "\tlibcudnn_cnn_infer.so.8 -> libcudnn_cnn_infer.so.8.1.1\n",
            "\tlibcudnn_cnn_train.so.8 -> libcudnn_cnn_train.so.8.1.1\n",
            "\tlibcudnn.so.8 -> libcudnn.so.8.1.1\n",
            "\tlibcudnn_ops_infer.so.8 -> libcudnn_ops_infer.so.8.1.1\n",
            "\tlibgeos-3.6.2.so -> libgeos-3.6.2.so\n",
            "\tlibboost_fiber.so.1.65.1 -> libboost_fiber.so.1.65.1\n",
            "\tlibboost_iostreams.so.1.65.1 -> libboost_iostreams.so.1.65.1\n",
            "\tlibboost_math_c99f.so.1.65.1 -> libboost_math_c99f.so.1.65.1\n",
            "\tlibchromaprint.so.1 -> libchromaprint.so.1.4.3\n",
            "\tlibplc4.so -> libplc4.so\n",
            "\tlibvtkViewsGeovisPython27D-6.3.so.6.3 -> libvtkViewsGeovisPython27D-6.3.so.6.3.0\n",
            "\tlibaec.so.0 -> libaec.so.0.0.3\n",
            "\tlibvtkIOVideoTCL-6.3.so.6.3 -> libvtkIOVideoTCL-6.3.so.6.3.0\n",
            "\tlibip4tc.so.0 -> libip4tc.so.0.1.0\n",
            "\tlibgdk_pixbuf-2.0.so.0 -> libgdk_pixbuf-2.0.so.0.3611.0\n",
            "\tlibxkbcommon.so.0 -> libxkbcommon.so.0.0.0\n",
            "\tlibboost_random.so.1.65.1 -> libboost_random.so.1.65.1\n",
            "\tlibnvidia-tls.so.525.60.13 -> libnvidia-tls.so.525.60.13\n",
            "\tlibfontconfig.so.1 -> libfontconfig.so.1.10.1\n",
            "\tlibobjc_gc.so.4 -> libobjc_gc.so.4.0.0\n",
            "\tlibvtkFiltersStatistics-6.3.so.6.3 -> libvtkFiltersStatistics-6.3.so.6.3.0\n",
            "\tlibsqlite3.so.0 -> libsqlite3.so.0.8.6\n",
            "\tlibCharLS.so.1 -> libCharLS.so.1.0\n",
            "\tlibvtkIOMPIParallelPython27D-6.3.so.6.3 -> libvtkIOMPIParallelPython27D-6.3.so.6.3.0\n",
            "\tlibvtkViewsGeovis-6.3.so.6.3 -> libvtkViewsGeovis-6.3.so.6.3.0\n",
            "\tlibnghttp2.so.14 -> libnghttp2.so.14.15.2\n",
            "\tlibzmq.so.5 -> libzmq.so.5.1.5\n",
            "\tlibvtkImagingColorTCL-6.3.so.6.3 -> libvtkImagingColorTCL-6.3.so.6.3.0\n",
            "\tlibssl3.so -> libssl3.so\n",
            "\tlibvtkIOODBCTCL-6.3.so.6.3 -> libvtkIOODBCTCL-6.3.so.6.3.0\n",
            "\tlibvtkWrappingPython27Core-6.3.so.6.3 -> libvtkWrappingPython27Core-6.3.so.6.3.0\n",
            "\tlibcudadebugger.so.1 -> libcudadebugger.so.525.60.13\n",
            "\tlibvtkFiltersGenericPython27D-6.3.so.6.3 -> libvtkFiltersGenericPython27D-6.3.so.6.3.0\n",
            "\tliblapack_atlas.so.3 -> liblapack_atlas.so.3.10.3\n",
            "\tlibvtkIOCorePython27D-6.3.so.6.3 -> libvtkIOCorePython27D-6.3.so.6.3.0\n",
            "\tlibvorbis.so.0 -> libvorbis.so.0.4.8\n",
            "\tlibboost_locale.so.1.65.1 -> libboost_locale.so.1.65.1\n",
            "\tlibvtkCommonMisc-6.3.so.6.3 -> libvtkCommonMisc-6.3.so.6.3.0\n",
            "\tlibnetcdf.so.13 -> libnetcdf.so.13\n",
            "\tlibvtkFiltersSelectionPython27D-6.3.so.6.3 -> libvtkFiltersSelectionPython27D-6.3.so.6.3.0\n",
            "\tlibboost_chrono.so.1.65.1 -> libboost_chrono.so.1.65.1\n",
            "\tlibvtkIOParallelExodusPython27D-6.3.so.6.3 -> libvtkIOParallelExodusPython27D-6.3.so.6.3.0\n",
            "\tlibfftw3.so.3 -> libfftw3.so.3.5.7\n",
            "\tlibavresample.so.3 -> libavresample.so.3.7.0\n",
            "\tlibvtkIOODBCPython27D-6.3.so.6.3 -> libvtkIOODBCPython27D-6.3.so.6.3.0\n",
            "\tlibboost_wave.so.1.65.1 -> libboost_wave.so.1.65.1\n",
            "\tlibhttp_parser.so.2.7.1 -> libhttp_parser.so.2.7.1\n",
            "\tlibnssutil3.so -> libnssutil3.so\n",
            "\tlibLLVM-10.so.1 -> libLLVM-10.so.1\n",
            "\tlibvtkIOSQLPython27D-6.3.so.6.3 -> libvtkIOSQLPython27D-6.3.so.6.3.0\n",
            "\tlibgdcmIOD.so.2.8 -> libgdcmIOD.so.2.8.4\n",
            "\tlibhdf5_serial_hl.so.100 -> libhdf5_serial_hl.so.100.0.0\n",
            "\tlibopencv_saliency.so.3.2 -> libopencv_saliency.so.3.2.0\n",
            "\tlibx265.so.146 -> libx265.so.146\n",
            "\tlibvtkParallelMPIPython27D-6.3.so.6.3 -> libvtkParallelMPIPython27D-6.3.so.6.3.0\n",
            "\tlibopencv_video.so.3.2 -> libopencv_video.so.3.2.0\n",
            "\tlibgtk-3.so.0 -> libgtk-3.so.0.2200.30\n",
            "\tlibvtkIOParallelLSDyna-6.3.so.6.3 -> libvtkIOParallelLSDyna-6.3.so.6.3.0\n",
            "\tlibboost_stacktrace_basic.so.1.65.1 -> libboost_stacktrace_basic.so.1.65.1\n",
            "\tlibflite_usenglish.so.1 -> libflite_usenglish.so.2.1\n",
            "\tlibnvidia-egl-gbm.so.1 -> libnvidia-egl-gbm.so.1.1.0\n",
            "\tlibGLdispatch.so.0 -> libGLdispatch.so.0.0.0\n",
            "\tlibvtkFiltersParallelTCL-6.3.so.6.3 -> libvtkFiltersParallelTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOExodus-6.3.so.6.3 -> libvtkIOExodus-6.3.so.6.3.0\n",
            "\tlibvtkIOFFMPEG-6.3.so.6.3 -> libvtkIOFFMPEG-6.3.so.6.3.0\n",
            "\tlibsuperlu.so.5 -> libsuperlu.so.5.2.1\n",
            "\tlibavahi-client.so.3 -> libavahi-client.so.3.2.9\n",
            "\tlibvtkRenderingImageTCL-6.3.so.6.3 -> libvtkRenderingImageTCL-6.3.so.6.3.0\n",
            "\tlibboost_log_setup.so.1.65.1 -> libboost_log_setup.so.1.65.1\n",
            "\tlibvtkFiltersPython-6.3.so.6.3 -> libvtkFiltersPython-6.3.so.6.3.0\n",
            "\tlibgl2ps.so.1.4 -> libgl2ps.so.1.4.0\n",
            "\tlibQt5Network.so.5 -> libQt5Network.so.5.9.5\n",
            "\tlibvtkFiltersHybridPython27D-6.3.so.6.3 -> libvtkFiltersHybridPython27D-6.3.so.6.3.0\n",
            "\tlibnorm.so.1 -> libnorm.so.1.0.0\n",
            "\tlibnvidia-nvvm.so.4 -> libnvidia-nvvm.so.525.60.13\n",
            "\tlibvtkFiltersModeling-6.3.so.6.3 -> libvtkFiltersModeling-6.3.so.6.3.0\n",
            "\tlibboost_atomic.so.1.65.1 -> libboost_atomic.so.1.65.1\n",
            "\tlibvtkIOMySQL-6.3.so.6.3 -> libvtkIOMySQL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersExtractionPython27D-6.3.so.6.3 -> libvtkFiltersExtractionPython27D-6.3.so.6.3.0\n",
            "\tlibx264.so.152 -> libx264.so.152\n",
            "\tlibgc.so.1 -> libgc.so.1.0.3\n",
            "\tlibboost_filesystem.so.1.65.1 -> libboost_filesystem.so.1.65.1\n",
            "\tlibQt5Test.so.5 -> libQt5Test.so.5.9.5\n",
            "\tlibxcb-sync.so.1 -> libxcb-sync.so.1.0.0\n",
            "\tlibvtkCommonMathTCL-6.3.so.6.3 -> libvtkCommonMathTCL-6.3.so.6.3.0\n",
            "\tlibopencv_highgui.so.3.2 -> libopencv_highgui.so.3.2.0\n",
            "\tlibflite.so.1 -> libflite.so.2.1\n",
            "\tlibwayland-client.so.0 -> libwayland-client.so.0.3.0\n",
            "\tlibopencv_dpm.so.3.2 -> libopencv_dpm.so.3.2.0\n",
            "\tlibvtkRenderingContextOpenGL-6.3.so.6.3 -> libvtkRenderingContextOpenGL-6.3.so.6.3.0\n",
            "\tlibwebp.so.6 -> libwebp.so.6.0.2\n",
            "\tlibvtkIOGeometryPython27D-6.3.so.6.3 -> libvtkIOGeometryPython27D-6.3.so.6.3.0\n",
            "\tlibboost_stacktrace_addr2line.so.1.65.1 -> libboost_stacktrace_addr2line.so.1.65.1\n",
            "\tlibpostproc.so.54 -> libpostproc.so.54.7.100\n",
            "\tlibpoppler.so.73 -> libpoppler.so.73.0.0\n",
            "\tlibinput.so.10 -> libinput.so.10.13.0\n",
            "\tlibgccpp.so.1 -> libgccpp.so.1.0.3\n",
            "\tlibvtkIOXMLParser-6.3.so.6.3 -> libvtkIOXMLParser-6.3.so.6.3.0\n",
            "\tlibvtkRenderingVolumePython27D-6.3.so.6.3 -> libvtkRenderingVolumePython27D-6.3.so.6.3.0\n",
            "\tlibpgm-5.2.so.0 -> libpgm-5.2.so.0.0.122\n",
            "\tlibSM.so.6 -> libSM.so.6.0.1\n",
            "\tlibpopt.so.0 -> libpopt.so.0.0.0\n",
            "\tlibfygm.so.0 -> libfygm.so.0.0.0\n",
            "\tlibopencv_features2d.so.3.2 -> libopencv_features2d.so.3.2.0\n",
            "\tlibvtkChartsCoreTCL-6.3.so.6.3 -> libvtkChartsCoreTCL-6.3.so.6.3.0\n",
            "\tlibkmlconvenience.so.1 -> libkmlconvenience.so.1.3.0\n",
            "\tlibICE.so.6 -> libICE.so.6.3.0\n",
            "\tlibompitrace.so.20 -> libompitrace.so.20.10.0\n",
            "\tlibvtkFiltersParallelMPIPython27D-6.3.so.6.3 -> libvtkFiltersParallelMPIPython27D-6.3.so.6.3.0\n",
            "\tlibedit.so.2 -> libedit.so.2.0.56\n",
            "\tlibGLESv2_nvidia.so.2 -> libGLESv2_nvidia.so.525.60.13\n",
            "\tlibpython2.7.so.1.0 -> libpython2.7.so.1.0\n",
            "\tlibgsm.so.1 -> libgsm.so.1.0.12\n",
            "\tlibvtkParallelMPITCL-6.3.so.6.3 -> libvtkParallelMPITCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingFreeType-6.3.so.6.3 -> libvtkRenderingFreeType-6.3.so.6.3.0\n",
            "\tlibatk-bridge-2.0.so.0 -> libatk-bridge-2.0.so.0.0.0\n",
            "\tlibopus.so.0 -> libopus.so.0.5.2\n",
            "\tlibxkbfile.so.1 -> libxkbfile.so.1.0.2\n",
            "\tlibvtkFiltersParallelPython27D-6.3.so.6.3 -> libvtkFiltersParallelPython27D-6.3.so.6.3.0\n",
            "\tlibnvidia-api.so.1 -> libnvidia-api.so.1\n",
            "\tlibvtkImagingMorphological-6.3.so.6.3 -> libvtkImagingMorphological-6.3.so.6.3.0\n",
            "\tlibturbojpeg.so.0 -> libturbojpeg.so.0.1.0\n",
            "\tlibboost_signals.so.1.65.1 -> libboost_signals.so.1.65.1\n",
            "\tlibvtkRenderingLabel-6.3.so.6.3 -> libvtkRenderingLabel-6.3.so.6.3.0\n",
            "\tlibnvidia-cfg.so.1 -> libnvidia-cfg.so.525.60.13\n",
            "\tlibvtkImagingSources-6.3.so.6.3 -> libvtkImagingSources-6.3.so.6.3.0\n",
            "\tlibvtkverdict-6.3.so.6.3 -> libvtkverdict-6.3.so.6.3.0\n",
            "\tlibboost_wserialization.so.1.65.1 -> libboost_wserialization.so.1.65.1\n",
            "\tlibxcb-dri3.so.0 -> libxcb-dri3.so.0.0.0\n",
            "\tlibvtkFiltersExtraction-6.3.so.6.3 -> libvtkFiltersExtraction-6.3.so.6.3.0\n",
            "\tlibvtkViewsInfovisTCL-6.3.so.6.3 -> libvtkViewsInfovisTCL-6.3.so.6.3.0\n",
            "\tlibboost_unit_test_framework.so.1.65.1 -> libboost_unit_test_framework.so.1.65.1\n",
            "\tlibmbedtls.so.12 -> libmbedtls.so.2.16.0\n",
            "\tlibopen-rte.so.20 -> libopen-rte.so.20.10.1\n",
            "\tlibpathplan.so.4 -> libpathplan.so.4.0.0\n",
            "\tlibnvidia-glcore.so.525.60.13 -> libnvidia-glcore.so.525.60.13\n",
            "\tlibvtkRenderingGL2PS-6.3.so.6.3 -> libvtkRenderingGL2PS-6.3.so.6.3.0\n",
            "\tlibcgraph.so.6 -> libcgraph.so.6.0.0\n",
            "\tlibgdcmjpeg12.so.2.8 -> libgdcmjpeg12.so.2.8.4\n",
            "\tlibvtkFiltersFlowPathsPython27D-6.3.so.6.3 -> libvtkFiltersFlowPathsPython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersVerdictPython27D-6.3.so.6.3 -> libvtkFiltersVerdictPython27D-6.3.so.6.3.0\n",
            "\tlibboost_graph_parallel.so.1.65.1 -> libboost_graph_parallel.so.1.65.1\n",
            "\tlibvtkInteractionImagePython27D-6.3.so.6.3 -> libvtkInteractionImagePython27D-6.3.so.6.3.0\n",
            "\tlibmlx5.so.1 -> libmlx5.so.1.4.17.1\n",
            "\tlibsndio.so.6.1 -> libsndio.so.6.1\n",
            "\tlibvtkInfovisBoostGraphAlgorithms-6.3.so.6.3 -> libvtkInfovisBoostGraphAlgorithms-6.3.so.6.3.0\n",
            "\tlibopenjp2.so.7 -> libopenjp2.so.2.3.0\n",
            "\tlibboost_log.so.1.65.1 -> libboost_log.so.1.65.1\n",
            "\tlibboost_coroutine.so.1.65.1 -> libboost_coroutine.so.1.65.1\n",
            "\tlibvtkIOPLY-6.3.so.6.3 -> libvtkIOPLY-6.3.so.6.3.0\n",
            "\tlibvtkIOExodusPython27D-6.3.so.6.3 -> libvtkIOExodusPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOVideoPython27D-6.3.so.6.3 -> libvtkIOVideoPython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersSourcesTCL-6.3.so.6.3 -> libvtkFiltersSourcesTCL-6.3.so.6.3.0\n",
            "\tlibboost_thread.so.1.65.1 -> libboost_thread.so.1.65.1\n",
            "\tlibtiff.so.5 -> libtiff.so.5.3.0\n",
            "\tlibpolkit-agent-1.so.0 -> libpolkit-agent-1.so.0.0.0\n",
            "\tlibvtkIOParallel-6.3.so.6.3 -> libvtkIOParallel-6.3.so.6.3.0\n",
            "\tlibvtkFiltersSelection-6.3.so.6.3 -> libvtkFiltersSelection-6.3.so.6.3.0\n",
            "\tlibXmuu.so.1 -> libXmuu.so.1.0.0\n",
            "\tlibvtkImagingGeneral-6.3.so.6.3 -> libvtkImagingGeneral-6.3.so.6.3.0\n",
            "\tlibvtkParallelMPI4Py-6.3.so.6.3 -> libvtkParallelMPI4Py-6.3.so.6.3.0\n",
            "\tlibvtkIOImagePython27D-6.3.so.6.3 -> libvtkIOImagePython27D-6.3.so.6.3.0\n",
            "\tlibhdf5_openmpi_fortran.so.100 -> libhdf5_openmpi_fortran.so.100.0.1\n",
            "\tlibvtkRenderingCorePython27D-6.3.so.6.3 -> libvtkRenderingCorePython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersHyperTreePython27D-6.3.so.6.3 -> libvtkFiltersHyperTreePython27D-6.3.so.6.3.0\n",
            "\tlibopencv_videoio.so.3.2 -> libopencv_videoio.so.3.2.0\n",
            "\tlibgvc.so.6 -> libgvc.so.6.0.0\n",
            "\tlibboost_system.so.1.65.1 -> libboost_system.so.1.65.1\n",
            "\tlibvtkCommonComputationalGeometry-6.3.so.6.3 -> libvtkCommonComputationalGeometry-6.3.so.6.3.0\n",
            "\tlibpcre16.so.3 -> libpcre16.so.3.13.3\n",
            "\tlibvtkFiltersImagingPython27D-6.3.so.6.3 -> libvtkFiltersImagingPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOMINC-6.3.so.6.3 -> libvtkIOMINC-6.3.so.6.3.0\n",
            "\tlibvtkViewsCoreTCL-6.3.so.6.3 -> libvtkViewsCoreTCL-6.3.so.6.3.0\n",
            "\tlibpulse.so.0 -> libpulse.so.0.20.2\n",
            "\tlibvtkCommonColorTCL-6.3.so.6.3 -> libvtkCommonColorTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOEnSight-6.3.so.6.3 -> libvtkIOEnSight-6.3.so.6.3.0\n",
            "\tlibvtkTestingRenderingTCL-6.3.so.6.3 -> libvtkTestingRenderingTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersParallelFlowPathsPython27D-6.3.so.6.3 -> libvtkFiltersParallelFlowPathsPython27D-6.3.so.6.3.0\n",
            "\tlibtk8.6.so -> libtk8.6.so.0\n",
            "\tlibcairo-gobject.so.2 -> libcairo-gobject.so.2.11510.0\n",
            "\tlibvtkFiltersReebGraph-6.3.so.6.3 -> libvtkFiltersReebGraph-6.3.so.6.3.0\n",
            "\tlibvtkftgl-6.3.so.6.3 -> libvtkftgl-6.3.so.6.3.0\n",
            "\tlibopencv_reg.so.3.2 -> libopencv_reg.so.3.2.0\n",
            "\tlibpulse-simple.so.0 -> libpulse-simple.so.0.1.1\n",
            "\tlibvpx.so.5 -> libvpx.so.5.0.0\n",
            "\tlibvtkIOGDALTCL-6.3.so.6.3 -> libvtkIOGDALTCL-6.3.so.6.3.0\n",
            "\tlibzvbi.so.0 -> libzvbi.so.0.13.2\n",
            "\tlibopencv_viz.so.3.2 -> libopencv_viz.so.3.2.0\n",
            "\tlibdapserver.so.7 -> libdapserver.so.7.6.7\n",
            "\tlibdapclient.so.6 -> libdapclient.so.6.1.7\n",
            "\tlibvtkImagingCoreTCL-6.3.so.6.3 -> libvtkImagingCoreTCL-6.3.so.6.3.0\n",
            "\tlibfreexl.so.1 -> libfreexl.so.1.1.0\n",
            "\tlibvtkFiltersTexturePython27D-6.3.so.6.3 -> libvtkFiltersTexturePython27D-6.3.so.6.3.0\n",
            "\tlibgts-0.7.so.5 -> libgts-0.7.so.5.0.1\n",
            "\tlibhdf5_openmpi.so.100 -> libhdf5_openmpi.so.100.0.1\n",
            "\tlibQt5Sql.so.5 -> libQt5Sql.so.5.9.5\n",
            "\tlibmca_common_sm.so.20 -> libmca_common_sm.so.20.10.1\n",
            "\tlibvtkInfovisBoostGraphAlgorithmsPython27D-6.3.so.6.3 -> libvtkInfovisBoostGraphAlgorithmsPython27D-6.3.so.6.3.0\n",
            "\tlibvtkRenderingMatplotlibTCL-6.3.so.6.3 -> libvtkRenderingMatplotlibTCL-6.3.so.6.3.0\n",
            "\tlibX11-xcb.so.1 -> libX11-xcb.so.1.0.0\n",
            "\tlibboost_math_tr1f.so.1.65.1 -> libboost_math_tr1f.so.1.65.1\n",
            "\tlibXtst.so.6 -> libXtst.so.6.1.0\n",
            "\tlibvtkIOPostgreSQL-6.3.so.6.3 -> libvtkIOPostgreSQL-6.3.so.6.3.0\n",
            "\tlibtcmalloc_and_profiler.so.4 -> libtcmalloc_and_profiler.so.4.3.0\n",
            "\tlibpcre2-32.so.0 -> libpcre2-32.so.0.7.0\n",
            "\tlibkmlregionator.so.1 -> libkmlregionator.so.1.3.0\n",
            "\tlibvtkFiltersParallelImaging-6.3.so.6.3 -> libvtkFiltersParallelImaging-6.3.so.6.3.0\n",
            "\tlibavfilter.so.6 -> libavfilter.so.6.107.100\n",
            "\tlibvtkCommonTransformsPython27D-6.3.so.6.3 -> libvtkCommonTransformsPython27D-6.3.so.6.3.0\n",
            "\tlibtesseract.so.4 -> libtesseract.so.4.0.0\n",
            "\tlibvtkxdmf2-6.3.so.6.3 -> libvtkxdmf2-6.3.so.6.3.0\n",
            "\tlibdrm_radeon.so.1 -> libdrm_radeon.so.1.0.1\n",
            "\tlibvtkParallelMPI-6.3.so.6.3 -> libvtkParallelMPI-6.3.so.6.3.0\n",
            "\tlibgdcmDSED.so.2.8 -> libgdcmDSED.so.2.8.4\n",
            "\tlibvtkInteractionWidgets-6.3.so.6.3 -> libvtkInteractionWidgets-6.3.so.6.3.0\n",
            "\tlibvtkRenderingVolumeOpenGL-6.3.so.6.3 -> libvtkRenderingVolumeOpenGL-6.3.so.6.3.0\n",
            "\tlibvtkImagingMathPython27D-6.3.so.6.3 -> libvtkImagingMathPython27D-6.3.so.6.3.0\n",
            "\tlibatk-1.0.so.0 -> libatk-1.0.so.0.22810.1\n",
            "\tlibQt5Gui.so.5 -> libQt5Gui.so.5.9.5\n",
            "\tlibvtkImagingFourier-6.3.so.6.3 -> libvtkImagingFourier-6.3.so.6.3.0\n",
            "\tlibvtkFiltersFlowPathsTCL-6.3.so.6.3 -> libvtkFiltersFlowPathsTCL-6.3.so.6.3.0\n",
            "\tlibnspr4.so -> libnspr4.so\n",
            "\tlibpython3.8.so.1.0 -> libpython3.8.so.1.0\n",
            "\tlibnvidia-ml.so.1 -> libnvidia-ml.so.525.60.13\n",
            "\tlibvtkLocalExample-6.3.so.6.3 -> libvtkLocalExample-6.3.so.6.3.0\n",
            "\tlibcolord.so.2 -> libcolord.so.2.0.5\n",
            "\tlibvtkIOSQLTCL-6.3.so.6.3 -> libvtkIOSQLTCL-6.3.so.6.3.0\n",
            "\tlibswscale.so.4 -> libswscale.so.4.8.100\n",
            "\tlibgmodule-2.0.so.0 -> libgmodule-2.0.so.0.5600.4\n",
            "\tlibvtkFiltersPythonPython27D-6.3.so.6.3 -> libvtkFiltersPythonPython27D-6.3.so.6.3.0\n",
            "\tlibopencv_bgsegm.so.3.2 -> libopencv_bgsegm.so.3.2.0\n",
            "\tlibgirepository-1.0.so.1 -> libgirepository-1.0.so.1.0.0\n",
            "\tliblab_gamut.so.1 -> liblab_gamut.so.1.0.0\n",
            "\tlibvtkInteractionStyleTCL-6.3.so.6.3 -> libvtkInteractionStyleTCL-6.3.so.6.3.0\n",
            "\tlibopencv_stereo.so.3.2 -> libopencv_stereo.so.3.2.0\n",
            "\tlibvtkImagingHybridTCL-6.3.so.6.3 -> libvtkImagingHybridTCL-6.3.so.6.3.0\n",
            "\tlibopencv_xobjdetect.so.3.2 -> libopencv_xobjdetect.so.3.2.0\n",
            "\tlibboost_type_erasure.so.1.65.1 -> libboost_type_erasure.so.1.65.1\n",
            "\tlibvtkViewsContext2D-6.3.so.6.3 -> libvtkViewsContext2D-6.3.so.6.3.0\n",
            "\tlibmlx4.so.1 -> libmlx4.so.1.0.17.1\n",
            "\tlibX11.so.6 -> libX11.so.6.3.0\n",
            "\tlibopencv_datasets.so.3.2 -> libopencv_datasets.so.3.2.0\n",
            "\tlibgeotiff.so.2 -> libgeotiff.so.2.1.2\n",
            "\tlibopencv_line_descriptor.so.3.2 -> libopencv_line_descriptor.so.3.2.0\n",
            "\tlibxcb-render.so.0 -> libxcb-render.so.0.0.0\n",
            "\tlibvtkIOFFMPEGPython27D-6.3.so.6.3 -> libvtkIOFFMPEGPython27D-6.3.so.6.3.0\n",
            "\tlibxcb-glx.so.0 -> libxcb-glx.so.0.0.0\n",
            "\tlibpcrecpp.so.0 -> libpcrecpp.so.0.0.1\n",
            "\tlibvtkFiltersParallelMPITCL-6.3.so.6.3 -> libvtkFiltersParallelMPITCL-6.3.so.6.3.0\n",
            "\tlibvtkIOXMLParserTCL-6.3.so.6.3 -> libvtkIOXMLParserTCL-6.3.so.6.3.0\n",
            "\tlibvtkalglib-6.3.so.6.3 -> libvtkalglib-6.3.so.6.3.0\n",
            "\tlibnvidia-eglcore.so.525.60.13 -> libnvidia-eglcore.so.525.60.13\n",
            "\tlibvtkRenderingContextIIDTCL-6.3.so.6.3 -> libvtkRenderingContextIIDTCL-6.3.so.6.3.0\n",
            "\tlibmbedx509.so.0 -> libmbedx509.so.2.16.0\n",
            "\tlibcolordprivate.so.2 -> libcolordprivate.so.2.0.5\n",
            "\tlibfreetype.so.6 -> libfreetype.so.6.15.0\n",
            "\tlibcdt.so.5 -> libcdt.so.5.0.0\n",
            "\tlibsodium.so.23 -> libsodium.so.23.1.0\n",
            "\tlibboost_timer.so.1.65.1 -> libboost_timer.so.1.65.1\n",
            "\tlibvtkCommonExecutionModelTCL-6.3.so.6.3 -> libvtkCommonExecutionModelTCL-6.3.so.6.3.0\n",
            "\tlibqhull_r.so.7 -> libqhull_r.so.7.2.0\n",
            "\tlibpcre2-8.so.0 -> libpcre2-8.so.0.7.0\n",
            "\tlibvtkIOLSDyna-6.3.so.6.3 -> libvtkIOLSDyna-6.3.so.6.3.0\n",
            "\tlibpciaccess.so.0 -> libpciaccess.so.0.11.1\n",
            "\tlibicu-le-hb.so.0 -> libicu-le-hb.so.0.0.0\n",
            "\tlibjson-glib-1.0.so.0 -> libjson-glib-1.0.so.0.400.2\n",
            "\tlibkmlbase.so.1 -> libkmlbase.so.1.3.0\n",
            "\tlibvtkIOLegacyTCL-6.3.so.6.3 -> libvtkIOLegacyTCL-6.3.so.6.3.0\n",
            "\tlibdrm_intel.so.1 -> libdrm_intel.so.1.0.0\n",
            "\tlibboost_math_tr1l.so.1.65.1 -> libboost_math_tr1l.so.1.65.1\n",
            "\tlibboost_mpi.so.1.65.1 -> libboost_mpi.so.1.65.1\n",
            "\tlibvtkIOParallelTCL-6.3.so.6.3 -> libvtkIOParallelTCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingLIC-6.3.so.6.3 -> libvtkRenderingLIC-6.3.so.6.3.0\n",
            "\tlibvtkParallelCorePython27D-6.3.so.6.3 -> libvtkParallelCorePython27D-6.3.so.6.3.0\n",
            "\tlibvtkRenderingContext2D-6.3.so.6.3 -> libvtkRenderingContext2D-6.3.so.6.3.0\n",
            "\tlibcrystalhd.so.3 -> libcrystalhd.so.3.6\n",
            "\tlibvtkInfovisBoostGraphAlgorithmsTCL-6.3.so.6.3 -> libvtkInfovisBoostGraphAlgorithmsTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOMPIParallelTCL-6.3.so.6.3 -> libvtkIOMPIParallelTCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingParallelLIC-6.3.so.6.3 -> libvtkRenderingParallelLIC-6.3.so.6.3.0\n",
            "\tlibxcb-xinerama.so.0 -> libxcb-xinerama.so.0.0.0\n",
            "\tlibvtkIOXML-6.3.so.6.3 -> libvtkIOXML-6.3.so.6.3.0\n",
            "\tlibxcb-util.so.1 -> libxcb-util.so.1.0.0\n",
            "\tlibtiffxx.so.5 -> libtiffxx.so.5.3.0\n",
            "\tlibvtkIOCoreTCL-6.3.so.6.3 -> libvtkIOCoreTCL-6.3.so.6.3.0\n",
            "\tlibswresample.so.2 -> libswresample.so.2.9.100\n",
            "\tlibboost_graph.so.1.65.1 -> libboost_graph.so.1.65.1\n",
            "\tlibboost_math_c99.so.1.65.1 -> libboost_math_c99.so.1.65.1\n",
            "\tlibpcre32.so.3 -> libpcre32.so.3.13.3\n",
            "\tlibvtkViewsCorePython27D-6.3.so.6.3 -> libvtkViewsCorePython27D-6.3.so.6.3.0\n",
            "\tlibvtkRenderingLabelTCL-6.3.so.6.3 -> libvtkRenderingLabelTCL-6.3.so.6.3.0\n",
            "\tlibgfortran.so.4 -> libgfortran.so.4.0.0\n",
            "\tlibicudata.so.60 -> libicudata.so.60.2\n",
            "\tlibvtkGeovisCore-6.3.so.6.3 -> libvtkGeovisCore-6.3.so.6.3.0\n",
            "\tlibvtkIOXdmfIITCL-6.3.so.6.3 -> libvtkIOXdmfIITCL-6.3.so.6.3.0\n",
            "\tlibinfinipath.so.4 -> libinfinipath.so.4.0\n",
            "\tlibvtkIOImport-6.3.so.6.3 -> libvtkIOImport-6.3.so.6.3.0\n",
            "\tlibXcomposite.so.1 -> libXcomposite.so.1.0.0\n",
            "\tlibvtkIOSQL-6.3.so.6.3 -> libvtkIOSQL-6.3.so.6.3.0\n",
            "\tlibXmu.so.6 -> libXmu.so.6.2.0\n",
            "\tlibopencv_freetype.so.3.2 -> libopencv_freetype.so.3.2.0\n",
            "\tlibvtkCommonExecutionModel-6.3.so.6.3 -> libvtkCommonExecutionModel-6.3.so.6.3.0\n",
            "\tlibhdf5_serial_fortran.so.100 -> libhdf5_serial_fortran.so.100.0.1\n",
            "\tlibpcre2-16.so.0 -> libpcre2-16.so.0.7.0\n",
            "\tlibvtkRenderingLabelPython27D-6.3.so.6.3 -> libvtkRenderingLabelPython27D-6.3.so.6.3.0\n",
            "\tlibQt5EglFsKmsSupport.so.5 -> libQt5EglFsKmsSupport.so.5.9.5\n",
            "\tlibpaper.so.1 -> libpaper.so.1.1.2\n",
            "\tlibvtkFiltersProgrammableTCL-6.3.so.6.3 -> libvtkFiltersProgrammableTCL-6.3.so.6.3.0\n",
            "\tlibhdf5_serialhl_fortran.so.100 -> libhdf5_serialhl_fortran.so.100.0.0\n",
            "\tlibboost_container.so.1.65.1 -> libboost_container.so.1.65.1\n",
            "\tlibvtkFiltersTexture-6.3.so.6.3 -> libvtkFiltersTexture-6.3.so.6.3.0\n",
            "\tlibxcb-dri2.so.0 -> libxcb-dri2.so.0.0.0\n",
            "\tlibvtkCommonMiscTCL-6.3.so.6.3 -> libvtkCommonMiscTCL-6.3.so.6.3.0\n",
            "\tlibvtkParallelCoreTCL-6.3.so.6.3 -> libvtkParallelCoreTCL-6.3.so.6.3.0\n",
            "\tlibrest-0.7.so.0 -> librest-0.7.so.0.0.0\n",
            "\tlibcroco-0.6.so.3 -> libcroco-0.6.so.3.0.1\n",
            "\tlibvtkImagingHybrid-6.3.so.6.3 -> libvtkImagingHybrid-6.3.so.6.3.0\n",
            "\tlibvtkRenderingExternalTCL-6.3.so.6.3 -> libvtkRenderingExternalTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersGeneric-6.3.so.6.3 -> libvtkFiltersGeneric-6.3.so.6.3.0\n",
            "\tlibvtkIONetCDF-6.3.so.6.3 -> libvtkIONetCDF-6.3.so.6.3.0\n",
            "\tlibvtkImagingStencilPython27D-6.3.so.6.3 -> libvtkImagingStencilPython27D-6.3.so.6.3.0\n",
            "\tlibvtkViewsContext2DPython27D-6.3.so.6.3 -> libvtkViewsContext2DPython27D-6.3.so.6.3.0\n",
            "\tlibargon2.so.0 -> libargon2.so.0\n",
            "\tlibnvidia-fbc.so.1 -> libnvidia-fbc.so.525.60.13\n",
            "\tlibvtkIOParallelNetCDFTCL-6.3.so.6.3 -> libvtkIOParallelNetCDFTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersProgrammablePython27D-6.3.so.6.3 -> libvtkFiltersProgrammablePython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOAMRTCL-6.3.so.6.3 -> libvtkIOAMRTCL-6.3.so.6.3.0\n",
            "\tlibunwind-coredump.so.0 -> libunwind-coredump.so.0.0.0\n",
            "\tlibgssapi_krb5.so.2 -> libgssapi_krb5.so.2.2\n",
            "\tlibhdf5_openmpi_hl.so.100 -> libhdf5_openmpi_hl.so.100.0.0\n",
            "\tlibvtkDomainsChemistryPython27D-6.3.so.6.3 -> libvtkDomainsChemistryPython27D-6.3.so.6.3.0\n",
            "\tlibopencv_text.so.3.2 -> libopencv_text.so.3.2.0\n",
            "\tlibva-drm.so.2 -> libva-drm.so.2.100.0\n",
            "\tlibvtkCommonSystem-6.3.so.6.3 -> libvtkCommonSystem-6.3.so.6.3.0\n",
            "\tlibvtkIOMPIImage-6.3.so.6.3 -> libvtkIOMPIImage-6.3.so.6.3.0\n",
            "\tlibvtkRenderingVolumeTCL-6.3.so.6.3 -> libvtkRenderingVolumeTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersAMR-6.3.so.6.3 -> libvtkFiltersAMR-6.3.so.6.3.0\n",
            "\tlibnvcuvid.so.1 -> libnvcuvid.so.525.60.13\n",
            "\tlibmpi_java.so.20 -> libmpi_java.so.20.10.0\n",
            "\tlibvtkFiltersParallelFlowPathsTCL-6.3.so.6.3 -> libvtkFiltersParallelFlowPathsTCL-6.3.so.6.3.0\n",
            "\tlibvorbisenc.so.2 -> libvorbisenc.so.2.0.11\n",
            "\tlibvtkIOMovie-6.3.so.6.3 -> libvtkIOMovie-6.3.so.6.3.0\n",
            "\tlibvtkInfovisLayoutTCL-6.3.so.6.3 -> libvtkInfovisLayoutTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOImportPython27D-6.3.so.6.3 -> libvtkIOImportPython27D-6.3.so.6.3.0\n",
            "\tlibtbb.so.2 -> libtbb.so.2\n",
            "\tlibvtkRenderingExternal-6.3.so.6.3 -> libvtkRenderingExternal-6.3.so.6.3.0\n",
            "\tlibuv.so.1 -> libuv.so.1.0.0\n",
            "\tlibgdcmDICT.so.2.8 -> libgdcmDICT.so.2.8.4\n",
            "\tlibvtkIOAMR-6.3.so.6.3 -> libvtkIOAMR-6.3.so.6.3.0\n",
            "\tlibvtkRenderingContextOpenGLPython27D-6.3.so.6.3 -> libvtkRenderingContextOpenGLPython27D-6.3.so.6.3.0\n",
            "\tlibvtkRenderingOpenGL-6.3.so.6.3 -> libvtkRenderingOpenGL-6.3.so.6.3.0\n",
            "\tlibvtkInfovisLayout-6.3.so.6.3 -> libvtkInfovisLayout-6.3.so.6.3.0\n",
            "\tlibgbm.so.1 -> libgbm.so.1.0.0\n",
            "\tlibvtkFiltersExtractionTCL-6.3.so.6.3 -> libvtkFiltersExtractionTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOLegacy-6.3.so.6.3 -> libvtkIOLegacy-6.3.so.6.3.0\n",
            "\tlibvtkIOLSDynaPython27D-6.3.so.6.3 -> libvtkIOLSDynaPython27D-6.3.so.6.3.0\n",
            "\tlibvtkRenderingLICTCL-6.3.so.6.3 -> libvtkRenderingLICTCL-6.3.so.6.3.0\n",
            "\tlibtcmalloc_minimal.so.4 -> libtcmalloc_minimal.so.4.3.0\n",
            "\tlibk5crypto.so.3 -> libk5crypto.so.3.1\n",
            "\tlibvtkIOImage-6.3.so.6.3 -> libvtkIOImage-6.3.so.6.3.0\n",
            "\tlibvtkFiltersSMP-6.3.so.6.3 -> libvtkFiltersSMP-6.3.so.6.3.0\n",
            "\tlibltdl.so.7 -> libltdl.so.7.3.1\n",
            "\tlibvtkDomainsChemistryTCL-6.3.so.6.3 -> libvtkDomainsChemistryTCL-6.3.so.6.3.0\n",
            "\tlibmp3lame.so.0 -> libmp3lame.so.0.0.0\n",
            "\tlibopen-pal.so.20 -> libopen-pal.so.20.10.1\n",
            "\tlibgvpr.so.2 -> libgvpr.so.2.0.0\n",
            "\tlibkmlengine.so.1 -> libkmlengine.so.1.3.0\n",
            "\tlibvtkFiltersReebGraphTCL-6.3.so.6.3 -> libvtkFiltersReebGraphTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOXMLPython27D-6.3.so.6.3 -> libvtkIOXMLPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOExodusTCL-6.3.so.6.3 -> libvtkIOExodusTCL-6.3.so.6.3.0\n",
            "\tlibFLAC.so.8 -> libFLAC.so.8.3.0\n",
            "\tlibprotobuf.so.10 -> libprotobuf.so.10.0.0\n",
            "\tlibrbd.so.1 -> librbd.so.1.12.0\n",
            "\tlibvtkRenderingMatplotlibPython27D-6.3.so.6.3 -> libvtkRenderingMatplotlibPython27D-6.3.so.6.3.0\n",
            "\tlibrhash.so.0 -> librhash.so.0\n",
            "\tlibvtkCommonSystemTCL-6.3.so.6.3 -> libvtkCommonSystemTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersFlowPaths-6.3.so.6.3 -> libvtkFiltersFlowPaths-6.3.so.6.3.0\n",
            "\tlibopencv_xphoto.so.3.2 -> libopencv_xphoto.so.3.2.0\n",
            "\tlibqhull.so.7 -> libqhull.so.7.2.0\n",
            "\tlibjack.so.0 -> libjack.so.0.0.28\n",
            "\tlibvtkRenderingVolumeAMR-6.3.so.6.3 -> libvtkRenderingVolumeAMR-6.3.so.6.3.0\n",
            "\tlibXss.so.1 -> libXss.so.1.0.0\n",
            "\tlibvtkRenderingGLtoPSTCL-6.3.so.6.3 -> libvtkRenderingGLtoPSTCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingCore-6.3.so.6.3 -> libvtkRenderingCore-6.3.so.6.3.0\n",
            "\tlibplds4.so -> libplds4.so\n",
            "\tlibvtkIOEnSightTCL-6.3.so.6.3 -> libvtkIOEnSightTCL-6.3.so.6.3.0\n",
            "\tlibboost_numpy3-py36.so.1.65.1 -> libboost_numpy3.so\n",
            "\tlibpolkit-backend-1.so.0 -> libpolkit-backend-1.so.0.0.0\n",
            "\tlibopencv_superres.so.3.2 -> libopencv_superres.so.3.2.0\n",
            "\tlibXinerama.so.1 -> libXinerama.so.1.0.0\n",
            "\tlibvtkRenderingFreeTypeFontConfig-6.3.so.6.3 -> libvtkRenderingFreeTypeFontConfig-6.3.so.6.3.0\n",
            "\tlibvtkCommonCoreTCL-6.3.so.6.3 -> libvtkCommonCoreTCL-6.3.so.6.3.0\n",
            "\tlibtheoraenc.so.1 -> libtheoraenc.so.1.1.2\n",
            "\tlibrubberband.so.2 -> librubberband.so.2.1.0\n",
            "\tlibboost_numpy-py27.so.1.65.1 -> libboost_numpy.so\n",
            "\tlibvtkFiltersCorePython27D-6.3.so.6.3 -> libvtkFiltersCorePython27D-6.3.so.6.3.0\n",
            "\tlibpixman-1.so.0 -> libpixman-1.so.0.34.0\n",
            "\tlibxshmfence.so.1 -> libxshmfence.so.1.0.0\n",
            "\tlibpng16.so.16 -> libpng16.so.16.34.0\n",
            "\tlibjsoncpp.so.1 -> libjsoncpp.so.1.7.4\n",
            "\tlibpcsclite.so.1 -> libpcsclite.so.1.0.0\n",
            "\tlibvtkIOParallelXMLTCL-6.3.so.6.3 -> libvtkIOParallelXMLTCL-6.3.so.6.3.0\n",
            "\tlibEGL.so.1 -> libEGL.so.1.0.0\n",
            "\tlibssh-gcrypt_threads.so.4 -> libssh-gcrypt_threads.so.4.5.0\n",
            "\tlibvtkRenderingOpenGLTCL-6.3.so.6.3 -> libvtkRenderingOpenGLTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOGDAL-6.3.so.6.3 -> libvtkIOGDAL-6.3.so.6.3.0\n",
            "\tlibunwind.so.8 -> libunwind.so.8.0.1\n",
            "\tlibvtkFiltersHybridTCL-6.3.so.6.3 -> libvtkFiltersHybridTCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingParallel-6.3.so.6.3 -> libvtkRenderingParallel-6.3.so.6.3.0\n",
            "\tlibvtkRenderingVolume-6.3.so.6.3 -> libvtkRenderingVolume-6.3.so.6.3.0\n",
            "\tlibarpack.so.2 -> libarpack.so.2.0.0\n",
            "\tlibwayland-server.so.0 -> libwayland-server.so.0.1.0\n",
            "\tlibvtkIOLSDynaTCL-6.3.so.6.3 -> libvtkIOLSDynaTCL-6.3.so.6.3.0\n",
            "\tlibshine.so.3 -> libshine.so.3.0.1\n",
            "\tlibvtkFiltersVerdict-6.3.so.6.3 -> libvtkFiltersVerdict-6.3.so.6.3.0\n",
            "\tlibevdev.so.2 -> libevdev.so.2.1.20\n",
            "\tlibvtkFiltersGeometryTCL-6.3.so.6.3 -> libvtkFiltersGeometryTCL-6.3.so.6.3.0\n",
            "\tlibbs2b.so.0 -> libbs2b.so.0.0.0\n",
            "\tlibutempter.so.0 -> libutempter.so.1.1.6\n",
            "\tlibvtkIOGDALPython27D-6.3.so.6.3 -> libvtkIOGDALPython27D-6.3.so.6.3.0\n",
            "\tlibdrm_nouveau.so.2 -> libdrm_nouveau.so.2.0.0\n",
            "\tlibnuma.so.1 -> libnuma.so.1.0.0\n",
            "\tlibXft.so.2 -> libXft.so.2.3.2\n",
            "\tlibGL.so.1 -> libGL.so.1.0.0\n",
            "\tlibvtkImagingStencil-6.3.so.6.3 -> libvtkImagingStencil-6.3.so.6.3.0\n",
            "\tlibvtkFiltersImagingTCL-6.3.so.6.3 -> libvtkFiltersImagingTCL-6.3.so.6.3.0\n",
            "\tlibvtkTestingRenderingPython27D-6.3.so.6.3 -> libvtkTestingRenderingPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOPostgreSQLPython27D-6.3.so.6.3 -> libvtkIOPostgreSQLPython27D-6.3.so.6.3.0\n",
            "\tlibpolkit-gobject-1.so.0 -> libpolkit-gobject-1.so.0.0.0\n",
            "\tlibnetcdf_c++.so.4 -> libnetcdf_c++.so.4.2.0\n",
            "\tlibvtkIOCore-6.3.so.6.3 -> libvtkIOCore-6.3.so.6.3.0\n",
            "\tlibexslt.so.0 -> libexslt.so.0.8.17\n",
            "\tlibprotoc.so.10 -> libprotoc.so.10.0.0\n",
            "\tlibtheoradec.so.1 -> libtheoradec.so.1.1.4\n",
            "\tlibvtkFiltersAMRPython27D-6.3.so.6.3 -> libvtkFiltersAMRPython27D-6.3.so.6.3.0\n",
            "\tlibvtkImagingColor-6.3.so.6.3 -> libvtkImagingColor-6.3.so.6.3.0\n",
            "\tlibXi.so.6 -> libXi.so.6.1.0\n",
            "\tlibvtkTestingIOSQL-6.3.so.6.3 -> libvtkTestingIOSQL-6.3.so.6.3.0\n",
            "\tlibXext.so.6 -> libXext.so.6.4.0\n",
            "\tlibvtkImagingFourierPython27D-6.3.so.6.3 -> libvtkImagingFourierPython27D-6.3.so.6.3.0\n",
            "\tlibflite_cmu_indic_lang.so.1 -> libflite_cmu_indic_lang.so.2.1\n",
            "\tlibIex-2_2.so.12 -> libIex.so\n",
            "\tlibvtkIOImageTCL-6.3.so.6.3 -> libvtkIOImageTCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingParallelLICPython27D-6.3.so.6.3 -> libvtkRenderingParallelLICPython27D-6.3.so.6.3.0\n",
            "\tlibjbig.so.0 -> libjbig.so.0\n",
            "\tlibiculx.so.60 -> libiculx.so.60.2\n",
            "\tlibvtkTestingGenericBridge-6.3.so.6.3 -> libvtkTestingGenericBridge-6.3.so.6.3.0\n",
            "\tlibvtkCommonTransformsTCL-6.3.so.6.3 -> libvtkCommonTransformsTCL-6.3.so.6.3.0\n",
            "\tlibEGL_mesa.so.0 -> libEGL_mesa.so.0.0.0\n",
            "\tlibgraphite2.so.3 -> libgraphite2.so.3.0.1\n",
            "\tlibvtkIOVPICTCL-6.3.so.6.3 -> libvtkIOVPICTCL-6.3.so.6.3.0\n",
            "\tlibcaca++.so.0 -> libcaca++.so.0.99.19\n",
            "\tlibopencv_shape.so.3.2 -> libopencv_shape.so.3.2.0\n",
            "\tlibQt5Xml.so.5 -> libQt5Xml.so.5.9.5\n",
            "\tlibxcb-render-util.so.0 -> libxcb-render-util.so.0.0.0\n",
            "\tlibvtkFiltersParallelStatisticsPython27D-6.3.so.6.3 -> libvtkFiltersParallelStatisticsPython27D-6.3.so.6.3.0\n",
            "\tlibvtkRenderingImagePython27D-6.3.so.6.3 -> libvtkRenderingImagePython27D-6.3.so.6.3.0\n",
            "\tlibwacom.so.2 -> libwacom.so.2.6.1\n",
            "\tlibvtkCommonCore-6.3.so.6.3 -> libvtkCommonCore-6.3.so.6.3.0\n",
            "\tlibgif.so.7 -> libgif.so.7.0.0\n",
            "\tlibopencv_fuzzy.so.3.2 -> libopencv_fuzzy.so.3.2.0\n",
            "\tlibXdmcp.so.6 -> libXdmcp.so.6.0.0\n",
            "\tlibHalf.so.12 -> libHalf.so.12.0.0\n",
            "\tlibavc1394.so.0 -> libavc1394.so.0.3.0\n",
            "\tlibhdf5_cpp.so.100 -> libhdf5_cpp.so.100.0.0\n",
            "\tlibvtkCommonColor-6.3.so.6.3 -> libvtkCommonColor-6.3.so.6.3.0\n",
            "\tlibodbccr.so.2 -> libodbccr.so.2.0.0\n",
            "\tlibobjc.so.4 -> libobjc.so.4.0.0\n",
            "\tlibSDL2-2.0.so.0 -> libSDL2-2.0.so.0.8.0\n",
            "\tlibnvidia-glsi.so.525.60.13 -> libnvidia-glsi.so.525.60.13\n",
            "\tlibflite_cmu_us_awb.so.1 -> libflite_cmu_us_awb.so.2.1\n",
            "\tlibopencv_face.so.3.2 -> libopencv_face.so.3.2.0\n",
            "\tlibvtkFiltersImaging-6.3.so.6.3 -> libvtkFiltersImaging-6.3.so.6.3.0\n",
            "\tlibvtkFiltersGeneralPython27D-6.3.so.6.3 -> libvtkFiltersGeneralPython27D-6.3.so.6.3.0\n",
            "\tlibdconf.so.1 -> libdconf.so.1.0.0\n",
            "\tlibXdamage.so.1 -> libXdamage.so.1.1.0\n",
            "\tlibLLVM-6.0.so.1 -> libLLVM-6.0.so.1\n",
            "\tlibboost_serialization.so.1.65.1 -> libboost_serialization.so.1.65.1\n",
            "\tlibopencv_ximgproc.so.3.2 -> libopencv_ximgproc.so.3.2.0\n",
            "\tlibOpenGL.so.0 -> libOpenGL.so.0.0.0\n",
            "\tlibXNVCtrl.so.0 -> libXNVCtrl.so.0.0.0\n",
            "\tlibvtkFiltersCoreTCL-6.3.so.6.3 -> libvtkFiltersCoreTCL-6.3.so.6.3.0\n",
            "\tlibmpi_cxx.so.20 -> libmpi_cxx.so.20.10.0\n",
            "\tlibvtkRenderingExternalPython27D-6.3.so.6.3 -> libvtkRenderingExternalPython27D-6.3.so.6.3.0\n",
            "\tlibvtkCommonMathPython27D-6.3.so.6.3 -> libvtkCommonMathPython27D-6.3.so.6.3.0\n",
            "\tlibkmlxsd.so.1 -> libkmlxsd.so.1.3.0\n",
            "\tlibEGL_nvidia.so.0 -> libEGL_nvidia.so.525.60.13\n",
            "\tlibarchive.so.13 -> libarchive.so.13.2.2\n",
            "\tlibxcb-xfixes.so.0 -> libxcb-xfixes.so.0.0.0\n",
            "\tlibnvidia-encode.so.1 -> libnvidia-encode.so.525.60.13\n",
            "\tlibnvidia-opencl.so.1 -> libnvidia-opencl.so.525.60.13\n",
            "\tlibvtkFiltersParallel-6.3.so.6.3 -> libvtkFiltersParallel-6.3.so.6.3.0\n",
            "\tlibicuuc.so.60 -> libicuuc.so.60.2\n",
            "\tlibvtkImagingCore-6.3.so.6.3 -> libvtkImagingCore-6.3.so.6.3.0\n",
            "\tlibodbc.so.2 -> libodbc.so.2.0.0\n",
            "\tlibvtkFiltersSources-6.3.so.6.3 -> libvtkFiltersSources-6.3.so.6.3.0\n",
            "\tlibgeos_c.so.1 -> libgeos_c.so.1.10.2\n",
            "\tlibpsl.so.5 -> libpsl.so.5.2.0\n",
            "\tlibvtkImagingGeneralPython27D-6.3.so.6.3 -> libvtkImagingGeneralPython27D-6.3.so.6.3.0\n",
            "\tlibvtkCommonComputationalGeometryTCL-6.3.so.6.3 -> libvtkCommonComputationalGeometryTCL-6.3.so.6.3.0\n",
            "\tlibnvidia-ngx.so.1 -> libnvidia-ngx.so.525.60.13\n",
            "\tlibxml2.so.2 -> libxml2.so.2.9.4\n",
            "\tlibvtkImagingFourierTCL-6.3.so.6.3 -> libvtkImagingFourierTCL-6.3.so.6.3.0\n",
            "\tlibvtkCommonMiscPython27D-6.3.so.6.3 -> libvtkCommonMiscPython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersStatisticsTCL-6.3.so.6.3 -> libvtkFiltersStatisticsTCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingImage-6.3.so.6.3 -> libvtkRenderingImage-6.3.so.6.3.0\n",
            "\tlibvtkRenderingAnnotationTCL-6.3.so.6.3 -> libvtkRenderingAnnotationTCL-6.3.so.6.3.0\n",
            "\tlibgit2.so.27 -> libgit2.so.0.27.7\n",
            "\tlibvdpau.so.1 -> libvdpau.so.1.0.0\n",
            "\tlibibverbs.so.1 -> libibverbs.so.1.1.17.1\n",
            "\tlibopencv_flann.so.3.2 -> libopencv_flann.so.3.2.0\n",
            "\tlibvtkRenderingFreeTypePython27D-6.3.so.6.3 -> libvtkRenderingFreeTypePython27D-6.3.so.6.3.0\n",
            "\tlibopencv_ml.so.3.2 -> libopencv_ml.so.3.2.0\n",
            "\tlibvtkParallelMPI4PyPython27D-6.3.so.6.3 -> libvtkParallelMPI4PyPython27D-6.3.so.6.3.0\n",
            "\tlibflite_cmu_us_rms.so.1 -> libflite_cmu_us_rms.so.2.1\n",
            "\tlibvtkVPIC-6.3.so.6.3 -> libvtkVPIC-6.3.so.6.3.0\n",
            "\tlibvtkexoIIc-6.3.so.6.3 -> libvtkexoIIc-6.3.so.6.3.0\n",
            "\tlibvtkIOODBC-6.3.so.6.3 -> libvtkIOODBC-6.3.so.6.3.0\n",
            "\tlibmpi_usempi_ignore_tkr.so.20 -> libmpi_usempi_ignore_tkr.so.20.10.0\n",
            "\tlibnvidia-opticalflow.so.1 -> libnvidia-opticalflow.so.525.60.13\n",
            "\tlibvtkRenderingParallelPython27D-6.3.so.6.3 -> libvtkRenderingParallelPython27D-6.3.so.6.3.0\n",
            "\tlibXt.so.6 -> libXt.so.6.0.0\n",
            "\tlibvtkImagingGeneralTCL-6.3.so.6.3 -> libvtkImagingGeneralTCL-6.3.so.6.3.0\n",
            "\tlibepsilon.so.1 -> libepsilon.so.1.0.0\n",
            "\tlibhdf5_openmpihl_fortran.so.100 -> libhdf5_openmpihl_fortran.so.100.0.0\n",
            "\tlibvtkImagingMorphologicalPython27D-6.3.so.6.3 -> libvtkImagingMorphologicalPython27D-6.3.so.6.3.0\n",
            "\tlibvtkImagingStatistics-6.3.so.6.3 -> libvtkImagingStatistics-6.3.so.6.3.0\n",
            "\tlibIlmImf-2_2.so.22 -> libIlmImf.so\n",
            "\tlibvtkIOXdmf2Python27D-6.3.so.6.3 -> libvtkIOXdmf2Python27D-6.3.so.6.3.0\n",
            "\tlibwayland-egl.so.1 -> libwayland-egl.so.1.0.0\n",
            "\tlibvtkViewsGeovisTCL-6.3.so.6.3 -> libvtkViewsGeovisTCL-6.3.so.6.3.0\n",
            "\tlibopencv_surface_matching.so.3.2 -> libopencv_surface_matching.so.3.2.0\n",
            "\tlibvtkIOGeometryTCL-6.3.so.6.3 -> libvtkIOGeometryTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersGeometryPython27D-6.3.so.6.3 -> libvtkFiltersGeometryPython27D-6.3.so.6.3.0\n",
            "\tlibXxf86vm.so.1 -> libXxf86vm.so.1.0.0\n",
            "\tlibavcodec.so.57 -> libavcodec.so.57.107.100\n",
            "\tlibvtkIOImportTCL-6.3.so.6.3 -> libvtkIOImportTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOGeoJSONPython27D-6.3.so.6.3 -> libvtkIOGeoJSONPython27D-6.3.so.6.3.0\n",
            "\tlibXv.so.1 -> libXv.so.1.0.0\n",
            "\tlibhdf5_serial.so.100 -> libhdf5_serial.so.100.0.1\n",
            "\tlibvtkFiltersGeneral-6.3.so.6.3 -> libvtkFiltersGeneral-6.3.so.6.3.0\n",
            "\tlibxerces-c-3.2.so -> libxerces-c.so\n",
            "\tlibxkbcommon-x11.so.0 -> libxkbcommon-x11.so.0.0.0\n",
            "\tlibvtkIOMoviePython27D-6.3.so.6.3 -> libvtkIOMoviePython27D-6.3.so.6.3.0\n",
            "\tlibboost_mpi_python3-py36.so.1.65.1 -> libboost_mpi_python3.so\n",
            "\tlibvtkmetaio-6.3.so.6.3 -> libvtkmetaio-6.3.so.6.3.0\n",
            "\tlibboost_program_options.so.1.65.1 -> libboost_program_options.so.1.65.1\n",
            "\tlibvtkPythonInterpreter-6.3.so.6.3 -> libvtkPythonInterpreter-6.3.so.6.3.0\n",
            "\tlibasyncns.so.0 -> libasyncns.so.0.3.1\n",
            "\tlibvtkImagingSourcesPython27D-6.3.so.6.3 -> libvtkImagingSourcesPython27D-6.3.so.6.3.0\n",
            "\tlibXpm.so.4 -> libXpm.so.4.11.0\n",
            "\tlibapt-inst.so.2.0 -> libapt-inst.so.2.0.0\n",
            "\tlibvtkIOPLYPython27D-6.3.so.6.3 -> libvtkIOPLYPython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersParallelImagingTCL-6.3.so.6.3 -> libvtkFiltersParallelImagingTCL-6.3.so.6.3.0\n",
            "\tlibwayland-cursor.so.0 -> libwayland-cursor.so.0.0.0\n",
            "\tlibvtkRenderingVolumeOpenGLPython27D-6.3.so.6.3 -> libvtkRenderingVolumeOpenGLPython27D-6.3.so.6.3.0\n",
            "\tlibmpdec.so.2 -> libmpdec.so.2.4.2\n",
            "\tlibIlmThread-2_2.so.12 -> libIlmThread.so\n",
            "\tlibprofiler.so.0 -> libprofiler.so.0.4.8\n",
            "\tlibavahi-common.so.3 -> libavahi-common.so.3.5.3\n",
            "\tlibvtkRenderingVolumeOpenGLTCL-6.3.so.6.3 -> libvtkRenderingVolumeOpenGLTCL-6.3.so.6.3.0\n",
            "\tlibflite_cmulex.so.1 -> libflite_cmulex.so.2.1\n",
            "\tlibopencv_imgcodecs.so.3.2 -> libopencv_imgcodecs.so.3.2.0\n",
            "\tlibvtkCommonTransforms-6.3.so.6.3 -> libvtkCommonTransforms-6.3.so.6.3.0\n",
            "\tlibQt5Concurrent.so.5 -> libQt5Concurrent.so.5.9.5\n",
            "\tliblcms2.so.2 -> liblcms2.so.2.0.8\n",
            "\tlibvtkInteractionWidgetsPython27D-6.3.so.6.3 -> libvtkInteractionWidgetsPython27D-6.3.so.6.3.0\n",
            "\tlibsnappy.so.1 -> libsnappy.so.1.1.7\n",
            "\tlibgdcmMEXD.so.2.8 -> libgdcmMEXD.so.2.8.4\n",
            "\tlibflite_cmu_us_slt.so.1 -> libflite_cmu_us_slt.so.2.1\n",
            "\tlibvtkImagingHybridPython27D-6.3.so.6.3 -> libvtkImagingHybridPython27D-6.3.so.6.3.0\n",
            "\tlibtbbmalloc.so.2 -> libtbbmalloc.so.2\n",
            "\tlibvtkIOEnSightPython27D-6.3.so.6.3 -> libvtkIOEnSightPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOMovieTCL-6.3.so.6.3 -> libvtkIOMovieTCL-6.3.so.6.3.0\n",
            "\tlibxcb-shm.so.0 -> libxcb-shm.so.0.0.0\n",
            "\tlibGLESv2.so.2 -> libGLESv2.so.2.0.0\n",
            "\tlibvtkGeovisCoreTCL-6.3.so.6.3 -> libvtkGeovisCoreTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersSMPPython27D-6.3.so.6.3 -> libvtkFiltersSMPPython27D-6.3.so.6.3.0\n",
            "\tlibgio-2.0.so.0 -> libgio-2.0.so.0.5600.4\n",
            "\tlibxcb-xkb.so.1 -> libxcb-xkb.so.1.0.0\n",
            "\tlibflite_cmu_time_awb.so.1 -> libflite_cmu_time_awb.so.2.1\n",
            "\tlibboost_math_c99l.so.1.65.1 -> libboost_math_c99l.so.1.65.1\n",
            "\tlibpipeline.so.1 -> libpipeline.so.1.5.0\n",
            "\tlibtwolame.so.0 -> libtwolame.so.0.0.0\n",
            "\tlibfftw3_threads.so.3 -> libfftw3_threads.so.3.5.7\n",
            "\tlibvtkRenderingLICPython27D-6.3.so.6.3 -> libvtkRenderingLICPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOParallelExodusTCL-6.3.so.6.3 -> libvtkIOParallelExodusTCL-6.3.so.6.3.0\n",
            "\tlibopencv_imgproc.so.3.2 -> libopencv_imgproc.so.3.2.0\n",
            "\tlibxcb-image.so.0 -> libxcb-image.so.0.0.0\n",
            "\tlibkmldom.so.1 -> libkmldom.so.1.3.0\n",
            "\tlibexif.so.12 -> libexif.so.12.3.3\n",
            "\tlibepoxy.so.0 -> libepoxy.so.0.0.0\n",
            "\tlibavformat.so.57 -> libavformat.so.57.83.100\n",
            "\tlibjpeg.so.8 -> libjpeg.so.8.1.2\n",
            "\tlibvtkIOExport-6.3.so.6.3 -> libvtkIOExport-6.3.so.6.3.0\n",
            "\tlibvtkRenderingFreeTypeTCL-6.3.so.6.3 -> libvtkRenderingFreeTypeTCL-6.3.so.6.3.0\n",
            "\tlibgpm.so.2 -> libgpm.so.2\n",
            "\tlibvtkFiltersVerdictTCL-6.3.so.6.3 -> libvtkFiltersVerdictTCL-6.3.so.6.3.0\n",
            "\tlibvtkViewsCore-6.3.so.6.3 -> libvtkViewsCore-6.3.so.6.3.0\n",
            "\tlibvtkImagingColorPython27D-6.3.so.6.3 -> libvtkImagingColorPython27D-6.3.so.6.3.0\n",
            "\tliburiparser.so.1 -> liburiparser.so.1.0.20\n",
            "\tlibGLX_mesa.so.0 -> libGLX_mesa.so.0.0.0\n",
            "\tlibcdio_paranoia.so.2 -> libcdio_paranoia.so.2.0.0\n",
            "\tlibvtkInteractionStylePython27D-6.3.so.6.3 -> libvtkInteractionStylePython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersParallelStatistics-6.3.so.6.3 -> libvtkFiltersParallelStatistics-6.3.so.6.3.0\n",
            "\tlibXrender.so.1 -> libXrender.so.1.3.0\n",
            "\tlibgme.so.0 -> libgme.so.0.6.2\n",
            "\tlibvtkViewsContextIIDTCL-6.3.so.6.3 -> libvtkViewsContextIIDTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOVideo-6.3.so.6.3 -> libvtkIOVideo-6.3.so.6.3.0\n",
            "\tlibxcb-randr.so.0 -> libxcb-randr.so.0.1.0\n",
            "\tlibvtkImagingMathTCL-6.3.so.6.3 -> libvtkImagingMathTCL-6.3.so.6.3.0\n",
            "\tlibxcb-keysyms.so.1 -> libxcb-keysyms.so.1.0.0\n",
            "\tlibmysofa.so.0 -> libmysofa.so.0.5.1\n",
            "\tlibvtkIOAMRPython27D-6.3.so.6.3 -> libvtkIOAMRPython27D-6.3.so.6.3.0\n",
            "\tlibvtkLocalExampleTCL-6.3.so.6.3 -> libvtkLocalExampleTCL-6.3.so.6.3.0\n",
            "\tlibvtkParallelCore-6.3.so.6.3 -> libvtkParallelCore-6.3.so.6.3.0\n",
            "\tlibnvoptix.so.1 -> libnvoptix.so.525.60.13\n",
            "\tlibwavpack.so.1 -> libwavpack.so.1.2.0\n",
            "\tlibsoup-gnome-2.4.so.1 -> libsoup-gnome-2.4.so.1.8.0\n",
            "\tlibclang-6.0.so.1 -> libclang-6.0.so.1\n",
            "\tlibtcmalloc.so.4 -> libtcmalloc.so.4.3.0\n",
            "\tlibvtkDICOMParser-6.3.so.6.3 -> libvtkDICOMParser-6.3.so.6.3.0\n",
            "\tlibopencv_optflow.so.3.2 -> libopencv_optflow.so.3.2.0\n",
            "\tlibspeex.so.1 -> libspeex.so.1.5.0\n",
            "\tlibvtkImagingMorphologicalTCL-6.3.so.6.3 -> libvtkImagingMorphologicalTCL-6.3.so.6.3.0\n",
            "\tlibcairo.so.2 -> libcairo.so.2.11510.0\n",
            "\tlibxcb-icccm.so.4 -> libxcb-icccm.so.4.0.0\n",
            "\tlibopencv_core.so.3.2 -> libopencv_core.so.3.2.0\n",
            "\tlibvtkIOLegacyPython27D-6.3.so.6.3 -> libvtkIOLegacyPython27D-6.3.so.6.3.0\n",
            "\tlibvtkRenderingGL2PSPython27D-6.3.so.6.3 -> libvtkRenderingGL2PSPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOXMLTCL-6.3.so.6.3 -> libvtkIOXMLTCL-6.3.so.6.3.0\n",
            "\tlibrdmacm.so.1 -> librdmacm.so.1.1.17.1\n",
            "\tlibopencv_calib3d.so.3.2 -> libopencv_calib3d.so.3.2.0\n",
            "\tlibvtkCommonExecutionModelPython27D-6.3.so.6.3 -> libvtkCommonExecutionModelPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOMPIImagePython27D-6.3.so.6.3 -> libvtkIOMPIImagePython27D-6.3.so.6.3.0\n",
            "\tlibXfont2.so.2 -> libXfont2.so.2.0.0\n",
            "\tlibdrm_amdgpu.so.1 -> libdrm_amdgpu.so.1.0.0\n",
            "\tlibmbedcrypto.so.3 -> libmbedcrypto.so.2.16.0\n",
            "\tlibvtkRenderingAnnotation-6.3.so.6.3 -> libvtkRenderingAnnotation-6.3.so.6.3.0\n",
            "\tlibcurl.so.4 -> libcurl.so.4.5.0\n",
            "\tlibcdio.so.17 -> libcdio.so.17.0.0\n",
            "\tlibvtkRenderingContextOpenGLTCL-6.3.so.6.3 -> libvtkRenderingContextOpenGLTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersParallelGeometryTCL-6.3.so.6.3 -> libvtkFiltersParallelGeometryTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersParallelFlowPaths-6.3.so.6.3 -> libvtkFiltersParallelFlowPaths-6.3.so.6.3.0\n",
            "\tlibsoxr.so.0 -> libsoxr.so.0.1.1\n",
            "\tlibpangocairo-1.0.so.0 -> libpangocairo-1.0.so.0.4000.14\n",
            "\tlibasound.so.2 -> libasound.so.2.0.0\n",
            "\tlibvtkIOMPIImageTCL-6.3.so.6.3 -> libvtkIOMPIImageTCL-6.3.so.6.3.0\n",
            "\tlibjackserver.so.0 -> libjackserver.so.0.0.28\n",
            "\tlibboost_python3-py36.so.1.65.1 -> libboost_python3.so\n",
            "\tlibfftw3_omp.so.3 -> libfftw3_omp.so.3.5.7\n",
            "\tlibvtkIOGeoJSONTCL-6.3.so.6.3 -> libvtkIOGeoJSONTCL-6.3.so.6.3.0\n",
            "\tlibvtkIONetCDFTCL-6.3.so.6.3 -> libvtkIONetCDFTCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingVolumeAMRTCL-6.3.so.6.3 -> libvtkRenderingVolumeAMRTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOPostgreSQLTCL-6.3.so.6.3 -> libvtkIOPostgreSQLTCL-6.3.so.6.3.0\n",
            "\tlibIlmImfUtil-2_2.so.22 -> libIlmImfUtil.so\n",
            "\tlibGLESv1_CM_nvidia.so.1 -> libGLESv1_CM_nvidia.so.525.60.13\n",
            "\tlibGLESv1_CM.so.1 -> libGLESv1_CM.so.1.0.0\n",
            "\tlibvtkIOVPIC-6.3.so.6.3 -> libvtkIOVPIC-6.3.so.6.3.0\n",
            "\tlibvtkRenderingLOD-6.3.so.6.3 -> libvtkRenderingLOD-6.3.so.6.3.0\n",
            "\tlibboost_prg_exec_monitor.so.1.65.1 -> libboost_prg_exec_monitor.so.1.65.1\n",
            "\tlibcups.so.2 -> libcups.so.2\n",
            "\tlibvtkFiltersGenericTCL-6.3.so.6.3 -> libvtkFiltersGenericTCL-6.3.so.6.3.0\n",
            "\tlibmca_common_libfabric.so.20 -> libmca_common_libfabric.so.20.10.0\n",
            "\tlibva-x11.so.2 -> libva-x11.so.2.100.0\n",
            "\tlibthai.so.0 -> libthai.so.0.3.0\n",
            "\tlibrsvg-2.so.2 -> librsvg-2.so.2.40.20\n",
            "\tlibvtkIOMySQLTCL-6.3.so.6.3 -> libvtkIOMySQLTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOMINCTCL-6.3.so.6.3 -> libvtkIOMINCTCL-6.3.so.6.3.0\n",
            "\tlibssh2.so.1 -> libssh2.so.1.0.1\n",
            "\tlibavutil.so.55 -> libavutil.so.55.78.100\n",
            "\tlibvtkFiltersStatisticsPython27D-6.3.so.6.3 -> libvtkFiltersStatisticsPython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersTextureTCL-6.3.so.6.3 -> libvtkFiltersTextureTCL-6.3.so.6.3.0\n",
            "\tlibgdcmCommon.so.2.8 -> libgdcmCommon.so.2.8.4\n",
            "\tlibelf.so.1 -> libelf-0.170.so\n",
            "\tlibnvidia-allocator.so.1 -> libnvidia-allocator.so.525.60.13\n",
            "\tlibboost_math_tr1.so.1.65.1 -> libboost_math_tr1.so.1.65.1\n",
            "\tlibxvidcore.so.4 -> libxvidcore.so.4.3\n",
            "\tlibssl.so.1.0.0 -> libssl.so.1.0.0\n",
            "\tlibvtkFiltersSMPTCL-6.3.so.6.3 -> libvtkFiltersSMPTCL-6.3.so.6.3.0\n",
            "\tlibBlocksRuntime.so.0 -> libBlocksRuntime.so.0.0.0\n",
            "\tlibopencv_plot.so.3.2 -> libopencv_plot.so.3.2.0\n",
            "\tlibvtkIOPLYTCL-6.3.so.6.3 -> libvtkIOPLYTCL-6.3.so.6.3.0\n",
            "\tlibgobject-2.0.so.0 -> libgobject-2.0.so.0.5600.4\n",
            "\tlibvtkInfovisCoreTCL-6.3.so.6.3 -> libvtkInfovisCoreTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersHybrid-6.3.so.6.3 -> libvtkFiltersHybrid-6.3.so.6.3.0\n",
            "\tlibvtkFiltersHyperTree-6.3.so.6.3 -> libvtkFiltersHyperTree-6.3.so.6.3.0\n",
            "\tlibfabric.so.1 -> libfabric.so.1.9.3\n",
            "\tlibvtkIOInfovisPython27D-6.3.so.6.3 -> libvtkIOInfovisPython27D-6.3.so.6.3.0\n",
            "\tlibgudev-1.0.so.0 -> libgudev-1.0.so.0.2.0\n",
            "\tlibvtkGeovisCorePython27D-6.3.so.6.3 -> libvtkGeovisCorePython27D-6.3.so.6.3.0\n",
            "\tlibvtkRenderingParallelLICTCL-6.3.so.6.3 -> libvtkRenderingParallelLICTCL-6.3.so.6.3.0\n",
            "\tlibboost_python-py27.so.1.65.1 -> libboost_python.so\n",
            "\tlibvtkRenderingLODPython27D-6.3.so.6.3 -> libvtkRenderingLODPython27D-6.3.so.6.3.0\n",
            "\tlibcaca.so.0 -> libcaca.so.0.99.19\n",
            "\tlibvtkRenderingParallelTCL-6.3.so.6.3 -> libvtkRenderingParallelTCL-6.3.so.6.3.0\n",
            "\tlibvtkFiltersCore-6.3.so.6.3 -> libvtkFiltersCore-6.3.so.6.3.0\n",
            "\tlibjansson.so.4 -> libjansson.so.4.11.0\n",
            "\tlibtcl8.6.so -> libtcl8.6.so.0\n",
            "\tlibvtkFiltersReebGraphPython27D-6.3.so.6.3 -> libvtkFiltersReebGraphPython27D-6.3.so.6.3.0\n",
            "\tlibvtkInteractionWidgetsTCL-6.3.so.6.3 -> libvtkInteractionWidgetsTCL-6.3.so.6.3.0\n",
            "\tlibopencv_videostab.so.3.2 -> libopencv_videostab.so.3.2.0\n",
            "\tlibvtkImagingStatisticsTCL-6.3.so.6.3 -> libvtkImagingStatisticsTCL-6.3.so.6.3.0\n",
            "\tlibopencv_phase_unwrapping.so.3.2 -> libopencv_phase_unwrapping.so.3.2.0\n",
            "\tliblept.so.5 -> liblept.so.5.0.2\n",
            "\tlibvtkFiltersParallelGeometry-6.3.so.6.3 -> libvtkFiltersParallelGeometry-6.3.so.6.3.0\n",
            "\tlibvtkFiltersParallelMPI-6.3.so.6.3 -> libvtkFiltersParallelMPI-6.3.so.6.3.0\n",
            "\tlibvtkIOInfovis-6.3.so.6.3 -> libvtkIOInfovis-6.3.so.6.3.0\n",
            "\tlibgthread-2.0.so.0 -> libgthread-2.0.so.0.5600.4\n",
            "\tlibnvidia-ptxjitcompiler.so.1 -> libnvidia-ptxjitcompiler.so.525.60.13\n",
            "\tlibopencv_rgbd.so.3.2 -> libopencv_rgbd.so.3.2.0\n",
            "\tlibsocket++.so.1 -> libsocket++.so.1.0.2\n",
            "\tlibpango-1.0.so.0 -> libpango-1.0.so.0.4000.14\n",
            "\tlibvtkRenderingMatplotlib-6.3.so.6.3 -> libvtkRenderingMatplotlib-6.3.so.6.3.0\n",
            "\tlibvtkFiltersGeneralTCL-6.3.so.6.3 -> libvtkFiltersGeneralTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOVPICPython27D-6.3.so.6.3 -> libvtkIOVPICPython27D-6.3.so.6.3.0\n",
            "\tlibgdcmMSFF.so.2.8 -> libgdcmMSFF.so.2.8.4\n",
            "\tlibass.so.9 -> libass.so.9.0.2\n",
            "\tlibvtkImagingStencilTCL-6.3.so.6.3 -> libvtkImagingStencilTCL-6.3.so.6.3.0\n",
            "\tlibopencv_objdetect.so.3.2 -> libopencv_objdetect.so.3.2.0\n",
            "\tlibwebpmux.so.3 -> libwebpmux.so.3.0.1\n",
            "\tlibpython3.6m.so.1.0 -> libpython3.6m.so.1.0\n",
            "\tlibsz.so.2 -> libsz.so.2.0.1\n",
            "\tlibsensors.so.4 -> libsensors.so.4.4.0\n",
            "\tlibvtkRenderingOpenGLPython27D-6.3.so.6.3 -> libvtkRenderingOpenGLPython27D-6.3.so.6.3.0\n",
            "\tlibf77blas.so.3 -> libf77blas.so.3.10.3\n",
            "\tlibXrandr.so.2 -> libXrandr.so.2.2.0\n",
            "\tlibopencv_ccalib.so.3.2 -> libopencv_ccalib.so.3.2.0\n",
            "\tlibImath-2_2.so.12 -> libImath.so\n",
            "\tlibvtkFiltersHyperTreeTCL-6.3.so.6.3 -> libvtkFiltersHyperTreeTCL-6.3.so.6.3.0\n",
            "\tlibvtkInfovisLayoutPython27D-6.3.so.6.3 -> libvtkInfovisLayoutPython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersParallelStatisticsTCL-6.3.so.6.3 -> libvtkFiltersParallelStatisticsTCL-6.3.so.6.3.0\n",
            "\tlibzvbi-chains.so.0 -> libzvbi-chains.so.0.0.0\n",
            "\tlibvtkTestingRendering-6.3.so.6.3 -> libvtkTestingRendering-6.3.so.6.3.0\n",
            "\tlibfyba.so.0 -> libfyba.so.0.0.0\n",
            "\tlibvtkRenderingVolumeAMRPython27D-6.3.so.6.3 -> libvtkRenderingVolumeAMRPython27D-6.3.so.6.3.0\n",
            "\tlibdap.so.25 -> libdap.so.25.0.1\n",
            "\tlibopenblas.so.0 -> libopenblasp-r0.2.20.so\n",
            "\tlibharfbuzz-icu.so.0 -> libharfbuzz-icu.so.0.10702.0\n",
            "\tlibvtkImagingMath-6.3.so.6.3 -> libvtkImagingMath-6.3.so.6.3.0\n",
            "\tlibmtdev.so.1 -> libmtdev.so.1.0.0\n",
            "\tlibvtkFiltersModelingTCL-6.3.so.6.3 -> libvtkFiltersModelingTCL-6.3.so.6.3.0\n",
            "\tlibogg.so.0 -> libogg.so.0.8.2\n",
            "\tlibavdevice.so.57 -> libavdevice.so.57.10.100\n",
            "\tlibhdf5_hl_cpp.so.100 -> libhdf5_hl_cpp.so.100.0.0\n",
            "\tlibxcb-shape.so.0 -> libxcb-shape.so.0.0.0\n",
            "\tlibkrb5support.so.0 -> libkrb5support.so.0.1\n",
            "\tlibboost_date_time.so.1.65.1 -> libboost_date_time.so.1.65.1\n",
            "\tlibvtkCommonMath-6.3.so.6.3 -> libvtkCommonMath-6.3.so.6.3.0\n",
            "\tlibgdk_pixbuf_xlib-2.0.so.0 -> libgdk_pixbuf_xlib-2.0.so.0.3611.0\n",
            "\tlibtcmalloc_debug.so.4 -> libtcmalloc_debug.so.4.3.0\n",
            "\tlibGLU.so.1 -> libGLU.so.1.3.1\n",
            "\tlibicutest.so.60 -> libicutest.so.60.2\n",
            "\tlibvtkRenderingAnnotationPython27D-6.3.so.6.3 -> libvtkRenderingAnnotationPython27D-6.3.so.6.3.0\n",
            "\tlibvtkImagingCorePython27D-6.3.so.6.3 -> libvtkImagingCorePython27D-6.3.so.6.3.0\n",
            "\tlibharfbuzz.so.0 -> libharfbuzz.so.0.10702.0\n",
            "\tlibfyut.so.0 -> libfyut.so.0.0.0\n",
            "\tlibQt5PrintSupport.so.5 -> libQt5PrintSupport.so.5.9.5\n",
            "\tlibvtkIOExportTCL-6.3.so.6.3 -> libvtkIOExportTCL-6.3.so.6.3.0\n",
            "\tlibicui18n.so.60 -> libicui18n.so.60.2\n",
            "\tlibXau.so.6 -> libXau.so.6.0.0\n",
            "\tlibvtkCommonCorePython27D-6.3.so.6.3 -> libvtkCommonCorePython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOXMLParserPython27D-6.3.so.6.3 -> libvtkIOXMLParserPython27D-6.3.so.6.3.0\n",
            "\tlibicutu.so.60 -> libicutu.so.60.2\n",
            "\tlibssh-gcrypt.so.4 -> libssh-gcrypt.so.4.5.0\n",
            "\tlibXcursor.so.1 -> libXcursor.so.1.0.2\n",
            "\tlibproj.so.12 -> libproj.so.12.0.0\n",
            "\tlibatlas.so.3 -> libatlas.so.3.10.3\n",
            "\tlibvtkIOFFMPEGTCL-6.3.so.6.3 -> libvtkIOFFMPEGTCL-6.3.so.6.3.0\n",
            "\tlibminizip.so.1 -> libminizip.so.1.0.0\n",
            "\tlibopencv_bioinspired.so.3.2 -> libopencv_bioinspired.so.3.2.0\n",
            "\tlibvtkViewsInfovisPython27D-6.3.so.6.3 -> libvtkViewsInfovisPython27D-6.3.so.6.3.0\n",
            "\tlibxslt.so.1 -> libxslt.so.1.1.29\n",
            "\tlibvtkIOParallelLSDynaTCL-6.3.so.6.3 -> libvtkIOParallelLSDynaTCL-6.3.so.6.3.0\n",
            "\tlibsmime3.so -> libsmime3.so\n",
            "\tlibgphoto2.so.6 -> libgphoto2.so.6.0.0\n",
            "\tlibhwloc.so.5 -> libhwloc.so.5.7.6\n",
            "\tlibopenal.so.1 -> libopenal.so.1.18.2\n",
            "\tlibvtkInteractionImage-6.3.so.6.3 -> libvtkInteractionImage-6.3.so.6.3.0\n",
            "\tlibvtkIOMPIParallel-6.3.so.6.3 -> libvtkIOMPIParallel-6.3.so.6.3.0\n",
            "\tlibcrypto.so.1.0.0 -> libcrypto.so.1.0.0\n",
            "\tlibvtkFiltersGeometry-6.3.so.6.3 -> libvtkFiltersGeometry-6.3.so.6.3.0\n",
            "\tlibvtkFiltersParallelImagingPython27D-6.3.so.6.3 -> libvtkFiltersParallelImagingPython27D-6.3.so.6.3.0\n",
            "\tlibQt5Widgets.so.5 -> libQt5Widgets.so.5.9.5\n",
            "\tlibflite_cmu_grapheme_lang.so.1 -> libflite_cmu_grapheme_lang.so.2.1\n",
            "\tlibgdcmjpeg16.so.2.8 -> libgdcmjpeg16.so.2.8.4\n",
            "\tlibdouble-conversion.so.1 -> libdouble-conversion.so.1.0\n",
            "\tlibflite_cmu_indic_lex.so.1 -> libflite_cmu_indic_lex.so.2.1\n",
            "\tlibtheora.so.0 -> libtheora.so.0.3.10\n",
            "\tlibrom1394.so.0 -> librom1394.so.0.3.0\n",
            "\tlibvtkInteractionImageTCL-6.3.so.6.3 -> libvtkInteractionImageTCL-6.3.so.6.3.0\n",
            "\tlibbluray.so.2 -> libbluray.so.2.0.2\n",
            "\tlibopencv_photo.so.3.2 -> libopencv_photo.so.3.2.0\n",
            "\tlibvtkRenderingTkTCL-6.3.so.6.3 -> libvtkRenderingTkTCL-6.3.so.6.3.0\n",
            "\tlibvtkIOParallelNetCDFPython27D-6.3.so.6.3 -> libvtkIOParallelNetCDFPython27D-6.3.so.6.3.0\n",
            "\tlibOpenCL.so.1 -> libOpenCL.so.1.0.0\n",
            "\tlibvtkIOParallelXML-6.3.so.6.3 -> libvtkIOParallelXML-6.3.so.6.3.0\n",
            "\tlibmysqlclient.so.20 -> libmysqlclient.so.20.3.27\n",
            "\tlibmpi_mpifh.so.20 -> libmpi_mpifh.so.20.11.0\n",
            "\tlibpcre2-posix.so.2 -> libpcre2-posix.so.2.0.0\n",
            "\tlibwebpdemux.so.2 -> libwebpdemux.so.2.0.3\n",
            "\tlibvtkCommonColorPython27D-6.3.so.6.3 -> libvtkCommonColorPython27D-6.3.so.6.3.0\n",
            "\tlibflite_cmu_us_kal.so.1 -> libflite_cmu_us_kal.so.2.1\n",
            "\tlibflite_cmu_us_kal16.so.1 -> libflite_cmu_us_kal16.so.2.1\n",
            "\tlibvtksys-6.3.so.6.3 -> libvtksys-6.3.so.6.3.0\n",
            "\tlibopencv_aruco.so.3.2 -> libopencv_aruco.so.3.2.0\n",
            "\tlibvtkWrappingJava-6.3.so.6.3 -> libvtkWrappingJava-6.3.so.6.3.0\n",
            "\tlibboost_stacktrace_noop.so.1.65.1 -> libboost_stacktrace_noop.so.1.65.1\n",
            "\tlibvtkIOParallelLSDynaPython27D-6.3.so.6.3 -> libvtkIOParallelLSDynaPython27D-6.3.so.6.3.0\n",
            "\tlibopencv_hdf.so.3.2 -> libopencv_hdf.so.3.2.0\n",
            "\tlibvtkIOMINCPython27D-6.3.so.6.3 -> libvtkIOMINCPython27D-6.3.so.6.3.0\n",
            "\tlibdc1394.so.22 -> libdc1394.so.22.2.1\n",
            "\tlibsoup-2.4.so.1 -> libsoup-2.4.so.1.8.0\n",
            "\tlibopencv_stitching.so.3.2 -> libopencv_stitching.so.3.2.0\n",
            "\tlibvtkIOParallelPython27D-6.3.so.6.3 -> libvtkIOParallelPython27D-6.3.so.6.3.0\n",
            "\tlibvtkViewsInfovis-6.3.so.6.3 -> libvtkViewsInfovis-6.3.so.6.3.0\n",
            "\tlibvtkFiltersSelectionTCL-6.3.so.6.3 -> libvtkFiltersSelectionTCL-6.3.so.6.3.0\n",
            "\tlibvtkRenderingCoreTCL-6.3.so.6.3 -> libvtkRenderingCoreTCL-6.3.so.6.3.0\n",
            "\tlibvtkImagingSourcesTCL-6.3.so.6.3 -> libvtkImagingSourcesTCL-6.3.so.6.3.0\n",
            "\tlibgphoto2_port.so.12 -> libgphoto2_port.so.12.0.0\n",
            "\tlibvtkIONetCDFPython27D-6.3.so.6.3 -> libvtkIONetCDFPython27D-6.3.so.6.3.0\n",
            "\tlibcblas.so.3 -> libcblas.so.3.10.3\n",
            "\tlibQt5DBus.so.5 -> libQt5DBus.so.5.9.5\n",
            "\tlibicuio.so.60 -> libicuio.so.60.2\n",
            "\tlibvtkCommonDataModelTCL-6.3.so.6.3 -> libvtkCommonDataModelTCL-6.3.so.6.3.0\n",
            "\tlibvtkCommonComputationalGeometryPython27D-6.3.so.6.3 -> libvtkCommonComputationalGeometryPython27D-6.3.so.6.3.0\n",
            "\tlibXaw.so.7 -> libXaw7.so.7.0.0\n",
            "\tlibvtkImagingStatisticsPython27D-6.3.so.6.3 -> libvtkImagingStatisticsPython27D-6.3.so.6.3.0\n",
            "\tlibQt5EglFSDeviceIntegration.so.5 -> libQt5EglFSDeviceIntegration.so.5.9.5\n",
            "\tlibvtkIOGeometry-6.3.so.6.3 -> libvtkIOGeometry-6.3.so.6.3.0\n",
            "\tlibxcb.so.1 -> libxcb.so.1.1.0\n",
            "\tlibvtkFiltersSourcesPython27D-6.3.so.6.3 -> libvtkFiltersSourcesPython27D-6.3.so.6.3.0\n",
            "\tlibvtkFiltersAMRTCL-6.3.so.6.3 -> libvtkFiltersAMRTCL-6.3.so.6.3.0\n",
            "\tlibvtkInfovisCore-6.3.so.6.3 -> libvtkInfovisCore-6.3.so.6.3.0\n",
            "\tlibrados.so.2 -> librados.so.2.0.0\n",
            "\tlibvtkFiltersModelingPython27D-6.3.so.6.3 -> libvtkFiltersModelingPython27D-6.3.so.6.3.0\n",
            "\tlibkrb5.so.3 -> libkrb5.so.3.3\n",
            "\tlibvtkIOParallelXMLPython27D-6.3.so.6.3 -> libvtkIOParallelXMLPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOMySQLPython27D-6.3.so.6.3 -> libvtkIOMySQLPython27D-6.3.so.6.3.0\n",
            "\tlibnss3.so -> libnss3.so\n",
            "\tlibunwind-ptrace.so.0 -> libunwind-ptrace.so.0.0.0\n",
            "\tlibvtkFiltersProgrammable-6.3.so.6.3 -> libvtkFiltersProgrammable-6.3.so.6.3.0\n",
            "\tlibboost_regex.so.1.65.1 -> libboost_regex.so.1.65.1\n",
            "\tlibcuda.so.1 -> libcuda.so.525.60.13\n",
            "\tlibsndfile.so.1 -> libsndfile.so.1.0.28\n",
            "\tlibvtkChartsCore-6.3.so.6.3 -> libvtkChartsCore-6.3.so.6.3.0\n",
            "\tlibpangoft2-1.0.so.0 -> libpangoft2-1.0.so.0.4000.14\n",
            "\tlibopencv_structured_light.so.3.2 -> libopencv_structured_light.so.3.2.0\n",
            "\tlibvtkFiltersParallelGeometryPython27D-6.3.so.6.3 -> libvtkFiltersParallelGeometryPython27D-6.3.so.6.3.0\n",
            "\tlibGLX.so.0 -> libGLX.so.0.0.0\n",
            "\tlibvtkIOGeoJSON-6.3.so.6.3 -> libvtkIOGeoJSON-6.3.so.6.3.0\n",
            "\tlibspatialite.so.7 -> libspatialite.so.7.1.0\n",
            "\tlibvtkCommonDataModelPython27D-6.3.so.6.3 -> libvtkCommonDataModelPython27D-6.3.so.6.3.0\n",
            "\tlibnvidia-compiler.so.525.60.13 -> libnvidia-compiler.so.525.60.13\n",
            "\tlibfribidi.so.0 -> libfribidi.so.0.3.6\n",
            "\tlibvtkInteractionStyle-6.3.so.6.3 -> libvtkInteractionStyle-6.3.so.6.3.0\n",
            "\tlibva.so.2 -> libva.so.2.100.0\n",
            "\tlibglapi.so.0 -> libglapi.so.0.0.0\n",
            "\tlibnvidia-glvkspirv.so.525.60.13 -> libnvidia-glvkspirv.so.525.60.13\n",
            "\tlibmpg123.so.0 -> libmpg123.so.0.44.8\n",
            "\tlibatspi.so.0 -> libatspi.so.0.0.1\n",
            "\tlibfontenc.so.1 -> libfontenc.so.1.0.0\n",
            "\tlibevent-2.1.so.6 -> libevent-2.1.so.6.0.2\n",
            "\tlibdrm.so.2 -> libdrm.so.2.4.0\n",
            "\tlibXfixes.so.3 -> libXfixes.so.3.1.0\n",
            "\tlibvtkDomainsChemistry-6.3.so.6.3 -> libvtkDomainsChemistry-6.3.so.6.3.0\n",
            "\tlibnvidia-rtcore.so.525.60.13 -> libnvidia-rtcore.so.525.60.13\n",
            "\tlibIexMath-2_2.so.12 -> libIexMath.so\n",
            "\tlibvtkCommonSystemPython27D-6.3.so.6.3 -> libvtkCommonSystemPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOExportPython27D-6.3.so.6.3 -> libvtkIOExportPython27D-6.3.so.6.3.0\n",
            "\tlibvorbisfile.so.3 -> libvorbisfile.so.3.3.7\n",
            "\tlibraw1394.so.11 -> libraw1394.so.11.1.0\n",
            "\tlibgdk-3.so.0 -> libgdk-3.so.0.2200.30\n",
            "\tlibcdio_cdda.so.2 -> libcdio_cdda.so.2.0.0\n",
            "\tlibpq.so.5 -> libpq.so.5.10\n",
            "\tlibgdcmjpeg8.so.2.8 -> libgdcmjpeg8.so.2.8.4\n",
            "\tlibmpi.so.20 -> libmpi.so.20.10.1\n",
            "\tlibvtkRenderingLODTCL-6.3.so.6.3 -> libvtkRenderingLODTCL-6.3.so.6.3.0\n",
            "\tlibvtkInfovisCorePython27D-6.3.so.6.3 -> libvtkInfovisCorePython27D-6.3.so.6.3.0\n",
            "\tlibvtkPythonInterpreterTCL-6.3.so.6.3 -> libvtkPythonInterpreterTCL-6.3.so.6.3.0\n",
            "\tlibmpi_usempif08.so.20 -> libmpi_usempif08.so.20.10.0\n",
            "\tlibtbbmalloc_proxy.so.2 -> libtbbmalloc_proxy.so.2\n",
            "\tlibboost_stacktrace_backtrace.so.1.65.1 -> libboost_stacktrace_backtrace.so.1.65.1\n",
            "\tlibtcmalloc_minimal_debug.so.4 -> libtcmalloc_minimal_debug.so.4.3.0\n",
            "\tlibsamplerate.so.0 -> libsamplerate.so.0.1.8\n",
            "\tlibproxy.so.1 -> libproxy.so.1.0.0\n",
            "\tlibnl-route-3.so.200 -> libnl-route-3.so.200.24.0\n",
            "\tlibvtkCommonDataModel-6.3.so.6.3 -> libvtkCommonDataModel-6.3.so.6.3.0\n",
            "\tlibodbcinst.so.2 -> libodbcinst.so.2.0.0\n",
            "\tlibglib-2.0.so.0 -> libglib-2.0.so.0.5600.4\n",
            "\tlibharfbuzz-gobject.so.0 -> libharfbuzz-gobject.so.0.10702.0\n",
            "\tlibgd.so.3 -> libgd.so.3.0.5\n",
            "\tlibvtkIOParallelExodus-6.3.so.6.3 -> libvtkIOParallelExodus-6.3.so.6.3.0\n",
            "\tlibboost_mpi_python-py27.so.1.65.1 -> libboost_mpi_python.so\n",
            "\tlibexpatw.so.1 -> libexpatw.so.1.6.7\n",
            "\tlibdatrie.so.1 -> libdatrie.so.1.3.3\n",
            "\tlibrtmp.so.1 -> librtmp.so.1\n",
            "\tlibvtkChartsCorePython27D-6.3.so.6.3 -> libvtkChartsCorePython27D-6.3.so.6.3.0\n",
            "\tlibvtkPythonInterpreterPython27D-6.3.so.6.3 -> libvtkPythonInterpreterPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOParallelNetCDF-6.3.so.6.3 -> libvtkIOParallelNetCDF-6.3.so.6.3.0\n",
            "\tlibQt5XcbQpa.so.5 -> libQt5XcbQpa.so.5.9.5\n",
            "\tlibxcb-present.so.0 -> libxcb-present.so.0.0.0\n",
            "\tlibcurl-gnutls.so.4 -> libcurl-gnutls.so.4.5.0\n",
            "\tlibvtkRenderingContext2DPython27D-6.3.so.6.3 -> libvtkRenderingContext2DPython27D-6.3.so.6.3.0\n",
            "\tlibvtkIOInfovisTCL-6.3.so.6.3 -> libvtkIOInfovisTCL-6.3.so.6.3.0\n",
            "\tlibflite_cmu_grapheme_lex.so.1 -> libflite_cmu_grapheme_lex.so.2.1\n",
            "\tlibQt5Core.so.5 -> libQt5Core.so.5.9.5\n",
            "\tlibvtkIOXdmf2-6.3.so.6.3 -> libvtkIOXdmf2-6.3.so.6.3.0\n",
            "\tlibiec61883.so.0 -> libiec61883.so.0.1.1\n",
            "\tlibboost_context.so.1.65.1 -> libboost_context.so.1.65.1\n",
            "\tlibmca_common_verbs.so.20 -> libmca_common_verbs.so.20.10.0\n",
            "\tlibopenmpt.so.0 -> libopenmpt.so.0.1.1\n",
            "\tlibGLX_nvidia.so.0 -> libGLX_nvidia.so.525.60.13\n",
            "\tlibluajit-5.1.so.2 -> libluajit-5.1.so.2.1.0\n",
            "\tliblua5.1-c++.so.0 -> liblua5.1-c++.so.0.0.0\n",
            "\tliblua5.1.so.0 -> liblua5.1.so.0.0.0\n",
            "\tlibyaml-0.so.2 -> libyaml-0.so.2.0.5\n",
            "\tlibunwind-x86_64.so.8 -> libunwind-x86_64.so.8.0.1\n",
            "\tlibpanelw.so.5 -> libpanelw.so.5.9\n",
            "\tlibmenu.so.5 -> libmenu.so.5.9\n",
            "\tlibpcreposix.so.3 -> libpcreposix.so.3.13.3\n",
            "\tliblz4.so.1 -> liblz4.so.1.7.1\n",
            "\tlibsemanage.so.1 -> libsemanage.so.1\n",
            "\tlibapt-private.so.0.0 -> libapt-private.so.0.0.0\n",
            "\tlibformw.so.5 -> libformw.so.5.9\n",
            "\tlibpanel.so.5 -> libpanel.so.5.9\n",
            "\tlibapt-pkg.so.5.0 -> libapt-pkg.so.5.0.2\n",
            "\tlibffi.so.6 -> libffi.so.6.0.4\n",
            "\tlibtic.so.5 -> libtic.so.5.9\n",
            "\tlibgnutls.so.30 -> libgnutls.so.30.14.10\n",
            "\tlibgmp.so.10 -> libgmp.so.10.3.2\n",
            "\tlibnettle.so.6 -> libnettle.so.6.5\n",
            "\tlibhogweed.so.4 -> libhogweed.so.4.5\n",
            "\tlibtasn1.so.6 -> libtasn1.so.6.5.5\n",
            "\tlibp11-kit.so.0 -> libp11-kit.so.0.3.0\n",
            "\tlibstdc++.so.6 -> libstdc++.so.6.0.25\n",
            "\tlibmenuw.so.5 -> libmenuw.so.5.9\n",
            "\tlibform.so.5 -> libform.so.5.9\n",
            "\tlibidn2.so.0 -> libidn2.so.0.3.3\n",
            "\tlibdebconfclient.so.0 -> libdebconfclient.so.0.0.0\n",
            "\tlibdb-5.3.so -> libdb-5.3.so\n",
            "\tlibzstd.so.1 -> libzstd.so.1.3.3\n",
            "\tlibunistring.so.2 -> libunistring.so.2.1.0\n",
            "/lib32:\n",
            "\tlibc.so.6 -> libc-2.27.so\n",
            "\tlibmemusage.so -> libmemusage.so\n",
            "\tlibcidn.so.1 -> libcidn-2.27.so\n",
            "\tlibnss_nis.so.2 -> libnss_nis-2.27.so\n",
            "\tlibnss_files.so.2 -> libnss_files-2.27.so\n",
            "\tlibnsl.so.1 -> libnsl-2.27.so\n",
            "\tlibanl.so.1 -> libanl-2.27.so\n",
            "\tlibSegFault.so -> libSegFault.so\n",
            "\tlibthread_db.so.1 -> libthread_db-1.0.so\n",
            "\tlibdl.so.2 -> libdl-2.27.so\n",
            "\tlibrt.so.1 -> librt-2.27.so\n",
            "\tlibutil.so.1 -> libutil-2.27.so\n",
            "\tlibpcprofile.so -> libpcprofile.so\n",
            "\tlibpthread.so.0 -> libpthread-2.27.so\n",
            "\tld-linux.so.2 -> ld-2.27.so\n",
            "\tlibnss_dns.so.2 -> libnss_dns-2.27.so\n",
            "\tlibnss_hesiod.so.2 -> libnss_hesiod-2.27.so\n",
            "\tlibresolv.so.2 -> libresolv-2.27.so\n",
            "\tlibcrypt.so.1 -> libcrypt-2.27.so\n",
            "\tlibnss_compat.so.2 -> libnss_compat-2.27.so\n",
            "\tlibBrokenLocale.so.1 -> libBrokenLocale-2.27.so\n",
            "\tlibnss_nisplus.so.2 -> libnss_nisplus-2.27.so\n",
            "\tlibm.so.6 -> libm-2.27.so\n",
            "/usr/lib32:\n",
            "\tlibgcc_s.so.1 -> libgcc_s.so.1\n",
            "\tlibstdc++.so.6 -> libstdc++.so.6.0.25\n",
            "/lib:\n",
            "/usr/lib:\n",
            "\tlibnvidia-gtk3.so.525.60.13 -> libnvidia-gtk3.so.525.60.13\n",
            "\tlibdfalt.so.0 -> libdfalt.so.0.0.0\n",
            "\tlibnvidia-wayland-client.so.525.60.13 -> libnvidia-wayland-client.so.525.60.13\n",
            "\tlibBLTlite.2.5.so.8.6 -> libBLTlite.2.5.so.8.6\n",
            "\tlibBLT.2.5.so.8.6 -> libBLT.2.5.so.8.6\n",
            "\tlibgdal.so.20 -> libgdal.so.20.3.2\n",
            "\tlibogdi.so.3.2 -> libogdi.so.3.2\n",
            "\tlibarmadillo.so.8 -> libarmadillo.so.8.400.0\n",
            "\tlibvpf.so.3.2 -> libvpf.so.3.2\n",
            "\tlibann.so.0 -> libann.so.0.0.0\n",
            "\tlibmfhdfalt.so.0 -> libmfhdfalt.so.0.0.0\n",
            "\tlibnvidia-gtk2.so.525.60.13 -> libnvidia-gtk2.so.525.60.13\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "git clone https://github.com/google/sentencepiece.git \n",
        "cd sentencepiece\n",
        "mkdir build\n",
        "cd build\n",
        "cmake ..\n",
        "make -j $(nproc)\n",
        "sudo make install\n",
        "sudo ldconfig -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMn-Lfyvi0CD"
      },
      "outputs": [],
      "source": [
        "!spm_train --input=/content/gdrive/MyDrive/Jeevan/largemt/tgt_train.txt --model_prefix=english_voc --vocab_size=100000 --character_coverage=1.0 --model_type=bpe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_DrHTGA1Svk"
      },
      "outputs": [],
      "source": [
        "!spm_train --input=/content/gdrive/MyDrive/Jeevan/largemt/src_train.txt --model_prefix=hindi_voc --vocab_size=100000 --character_coverage=1.0 --model_type=bpe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUmZA0R0kPJ8"
      },
      "outputs": [],
      "source": [
        "!spm_encode --model=/content/hindi.model.model --output_format=piece /content/gdrive/MyDrive/Jeevan/mt/data/src_train.txt output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxvkLOZ8mFpX"
      },
      "outputs": [],
      "source": [
        "!cp /content/english_voc.model /content/gdrive/MyDrive/Jeevan/largemt/models/\n",
        "!cp /content/english_voc.vocab /content/gdrive/MyDrive/Jeevan/largemt/models/\n",
        "!cp /content/hindi_voc.model /content/gdrive/MyDrive/Jeevan/largemt/models/\n",
        "!cp /content/hindi_voc.vocab /content/gdrive/MyDrive/Jeevan/largemt/models/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYJD1b-Nt7bb"
      },
      "outputs": [],
      "source": [
        "!cp /content/data.yaml /content/gdrive/MyDrive/Jeevan/newmt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AEfS3_qjcW9"
      },
      "outputs": [],
      "source": [
        "!onmt-main --config /content/gdrive/MyDrive/Jeevan/newmt/data.yaml --auto_config infer --features_file /content/gdrive/MyDrive/Jeevan/mt/data/src_val.txt >new.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22DCFNYSjij7"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/gdrive/MyDrive/Jeevan/newmt/checkpoint/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLinM0nSyaFQ"
      },
      "outputs": [],
      "source": [
        "!onmt-build-vocab --from_vocab /content/gdrive/MyDrive/Jeevan/largemt/models/hindi_voc.vocab --from_format sentencepiece --save_vocab src_vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GwQaGz03P35"
      },
      "outputs": [],
      "source": [
        "!onmt-build-vocab --from_vocab /content/gdrive/MyDrive/Jeevan/largemt/models/english_voc.vocab --from_format sentencepiece --save_vocab tgt_vocab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31sexSnG8MpO"
      },
      "outputs": [],
      "source": [
        "!onmt-main --config /content/gdrive/MyDrive/Jeevan/largemt/data.yaml --auto_config export --output_dir /content/gdrive/MyDrive/Jeevan/largemt/models/   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng3gA6kBmOje"
      },
      "outputs": [],
      "source": [
        "!cp /content/src_vocab.txt /content/gdrive/MyDrive/Jeevan/largemt/\n",
        "!cp /content/tgt_vocab.txt /content/gdrive/MyDrive/Jeevan/largemt/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okoq0U-Vuxl-"
      },
      "outputs": [],
      "source": [
        "!onmt-main --model_type Transformer --config /content/gdrive/MyDrive/Jeevan/largemt/data.yaml --auto_config train --with_eval \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nei8XwYso81B"
      },
      "outputs": [],
      "source": [
        "!saved_model_cli show --dir /content/gdrive/MyDrive/Jeevan/newmt/models/ --tag_set serve --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_text as tft\n"
      ],
      "metadata": {
        "id": "ITqfs8M5mvRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from opennmt.tokenizers import tokenizer"
      ],
      "metadata": {
        "id": "ZrrTI2P2pteV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OG6JhN7DZO8"
      },
      "outputs": [],
      "source": [
        "\"\"\"SentencePiece tokenizer.\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SentencePieceTokenizer(tokenizer.TensorFlowTokenizer):\n",
        "    \"\"\"In-graph SentencePiece tokenizer using\n",
        "    ``tensorflow_text.SentencepieceTokenizer``.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, nbest_size=0, alpha=1.0):\n",
        "        \"\"\"Initializes the tokenizer.\n",
        "        Args:\n",
        "          model: Path to the SentencePiece model.\n",
        "          nbest_size: Number of candidates to sample from (disabled during inference).\n",
        "          alpha: Smoothing parameter for the sampling.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self._nbest_size = nbest_size\n",
        "        with tf.io.gfile.GFile(model, \"rb\") as model_file:\n",
        "            self._tokenizer = tft.SentencepieceTokenizer(\n",
        "                model=model_file.read(),\n",
        "                out_type=tf.string,\n",
        "                nbest_size=nbest_size,\n",
        "                alpha=alpha,\n",
        "            )\n",
        "    def _tokenize_tensor(self, text, training):\n",
        "        if not training:\n",
        "            self._tokenizer.nbest_size = 0\n",
        "        tokens = self._tokenizer.tokenize(text)\n",
        "        if not training:\n",
        "            self._tokenizer.nbest_size = self._nbest_size\n",
        "        return tokens\n",
        "\n",
        "    def _detokenize_tensor(self, tokens):\n",
        "        return self._tokenizer.detokenize(tokens)\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mbxuJvQ909wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5ot9tDOin0_"
      },
      "outputs": [],
      "source": [
        "from opennmt.tokenizers.sentencepiece_tokenizer import SentencePieceTokenizer\n",
        "a=SentencePieceTokenizer('/content/gdrive/MyDrive/Jeevan/mt/data/english.model.model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loadedd"
      ],
      "metadata": {
        "id": "r1ZUjAG9qBMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSrtPaLsiwcN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "982b7376-86da-4983-fa52-80d75f065be9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ef79aebc1b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloadedd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'what is my name'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: '_UserObject' object has no attribute '_tokenize_tensor'"
          ]
        }
      ],
      "source": [
        " b=loadedd._tokenize_tensor('what is my name',True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwmFjzKWkDO3"
      },
      "outputs": [],
      "source": [
        " unwanted_char=a._tokenize_tensor('what is my name',False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INxp2vbFk4bf"
      },
      "outputs": [],
      "source": [
        "!echo \"Hello world!\" | onmt-tokenize-text --tokenizer_config /content/sample_data/new.yaml >a.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uLIaXiNnovi"
      },
      "outputs": [],
      "source": [
        "with open('/content/a.txt','r') as r:\n",
        "  text=r.read()\n",
        "\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyutaRPPn7kF"
      },
      "outputs": [],
      "source": [
        "len(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QW6B-PwTn-eF"
      },
      "outputs": [],
      "source": [
        "#!wget https://s3.amazonaws.com/opennmt-models/averaged-ende-export500k-v2.tar.gz\n",
        "!tar xf averaged-ende-export500k-v2.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg5PTBLDpJix"
      },
      "outputs": [],
      "source": [
        "!python /content/sample_data/new.py ./averaged-ende-export500k-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRaCAiqLpjcc"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load('/content/gdrive/MyDrive/Jeevan/newmt/models')\n",
        "print(list(loaded.signatures.keys()))  # [\"serving_default\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5VcpE1LurSB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "0774b9c8-f0db-4fa6-9a32-c58ac3f91576"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7edbd3966ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs = {\n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0;34m\"im yashwanth\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         }\n",
            "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
          ]
        }
      ],
      "source": [
        "inputs = {\n",
        "            \"text\": tf.constant(b, dtype=tf.string)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPfPIGXbwq0t"
      },
      "outputs": [],
      "source": [
        "infer(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone \"https://github.com/tensorflow/serving\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CnhBFMO3NJd",
        "outputId": "a197d84c-2865-4644-9891-d2ce6cd9a6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'serving'...\n",
            "remote: Enumerating objects: 32411, done.\u001b[K\n",
            "remote: Counting objects: 100% (206/206), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 32411 (delta 126), reused 121 (delta 80), pack-reused 32205\u001b[K\n",
            "Receiving objects: 100% (32411/32411), 16.69 MiB | 22.43 MiB/s, done.\n",
            "Resolving deltas: 100% (26067/26067), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import tensorflow_serving"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "dfnm_WNA22np",
        "outputId": "bcfd062f-8c25-42cf-b038-4554fdf7777a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ed67ca70eb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'tensorflow_serving' from 'tensorflow' (/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Example of a translation client.\"\"\"\n",
        "\n",
        "import argparse\n",
        "\n",
        "import grpc\n",
        "import pyonmttok\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow_serving.apis import predict_pb2, prediction_service_pb2_grpc\n",
        "\n",
        "\n",
        "def pad_batch(batch_tokens):\n",
        "    \"\"\"Pads a batch of tokens.\"\"\"\n",
        "    lengths = [len(tokens) for tokens in batch_tokens]\n",
        "    max_length = max(lengths)\n",
        "    for tokens, length in zip(batch_tokens, lengths):\n",
        "        if max_length > length:\n",
        "            tokens += [\"\"] * (max_length - length)\n",
        "    return batch_tokens, lengths, max_length\n",
        "\n",
        "\n",
        "def extract_prediction(result):\n",
        "    \"\"\"Parses a translation result.\n",
        "\n",
        "    Args:\n",
        "      result: A `PredictResponse` proto.\n",
        "\n",
        "    Returns:\n",
        "      A generator over the hypotheses.\n",
        "    \"\"\"\n",
        "    batch_lengths = tf.make_ndarray(result.outputs[\"length\"])\n",
        "    batch_predictions = tf.make_ndarray(result.outputs[\"tokens\"])\n",
        "    for hypotheses, lengths in zip(batch_predictions, batch_lengths):\n",
        "        # Only consider the first hypothesis (the best one).\n",
        "        best_hypothesis = hypotheses[0].tolist()\n",
        "        best_length = lengths[0]\n",
        "        if best_hypothesis[best_length - 1] == b\"</s>\":\n",
        "            best_length -= 1\n",
        "        yield best_hypothesis[:best_length]\n",
        "\n",
        "\n",
        "def send_request(stub, model_name, batch_tokens, timeout=5.0):\n",
        "    \"\"\"Sends a translation request.\n",
        "\n",
        "    Args:\n",
        "      stub: The prediction service stub.\n",
        "      model_name: The model to request.\n",
        "      tokens: A list of tokens.\n",
        "      timeout: Timeout after this many seconds.\n",
        "\n",
        "    Returns:\n",
        "      A future.\n",
        "    \"\"\"\n",
        "    batch_tokens, lengths, max_length = pad_batch(batch_tokens)\n",
        "    batch_size = len(lengths)\n",
        "    request = predict_pb2.PredictRequest()\n",
        "    request.model_spec.name = model_name\n",
        "    request.inputs[\"tokens\"].CopyFrom(\n",
        "        tf.make_tensor_proto(\n",
        "            batch_tokens, dtype=tf.string, shape=(batch_size, max_length)\n",
        "        )\n",
        "    )\n",
        "    request.inputs[\"length\"].CopyFrom(\n",
        "        tf.make_tensor_proto(lengths, dtype=tf.int32, shape=(batch_size,))\n",
        "    )\n",
        "    return stub.Predict.future(request, timeout)\n",
        "\n",
        "\n",
        "def translate(stub, model_name, batch_text, tokenizer, timeout=5.0):\n",
        "    \"\"\"Translates a batch of sentences.\n",
        "\n",
        "    Args:\n",
        "      stub: The prediction service stub.\n",
        "      model_name: The model to request.\n",
        "      batch_text: A list of sentences.\n",
        "      tokenizer: The tokenizer to apply.\n",
        "      timeout: Timeout after this many seconds.\n",
        "\n",
        "    Returns:\n",
        "      A generator over the detokenized predictions.\n",
        "    \"\"\"\n",
        "    batch_input = [tokenizer.tokenize(text)[0] for text in batch_text]\n",
        "    future = send_request(stub, model_name, batch_input, timeout=timeout)\n",
        "    result = future.result()\n",
        "    batch_output = [\n",
        "        tokenizer.detokenize(prediction) for prediction in extract_prediction(result)\n",
        "    ]\n",
        "    return batch_output\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Translation client example\")\n",
        "    parser.add_argument(\"--model_name\", required=True, help=\"model name\")\n",
        "    parser.add_argument(\n",
        "        \"--sentencepiece_model\", required=True, help=\"path to the sentence model\"\n",
        "    )\n",
        "    parser.add_argument(\"--host\", default=\"localhost\", help=\"model server host\")\n",
        "    parser.add_argument(\"--port\", type=int, default=9000, help=\"model server port\")\n",
        "    parser.add_argument(\"--timeout\", type=float, default=10.0, help=\"request timeout\")\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    channel = grpc.insecure_channel(\"%s:%d\" % (args.host, args.port))\n",
        "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "    tokenizer = pyonmttok.Tokenizer(\"none\", sp_model_path=args.sentencepiece_model)\n",
        "\n",
        "    while True:\n",
        "        text = input(\"Source: \")\n",
        "        output = translate(\n",
        "            stub, args.model_name, [text], tokenizer, timeout=args.timeout\n",
        "        )\n",
        "        print(\"Target: %s\" % output[0])\n",
        "        print(\"\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "wR1V5iJG2wIr",
        "outputId": "863c9e20-1cd8-4a52-927f-7837818e2e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1a770bb12435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_serving\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_pb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_service_pb2_grpc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_serving'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "saved_model_cli show --dir /content/gdrive/MyDrive/MT \\\n",
        "    --tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83zgokXqx1pC",
        "outputId": "cf4f2dbb-5429-4024-a25f-5d7f1d0895a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['length'] tensor_info:\n",
            "      dtype: DT_INT32\n",
            "      shape: (-1)\n",
            "      name: serving_default_length:0\n",
            "  inputs['tokens'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1, -1)\n",
            "      name: serving_default_tokens:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['alignment'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 1, -1, -1)\n",
            "      name: StatefulPartitionedCall:0\n",
            "  outputs['length'] tensor_info:\n",
            "      dtype: DT_INT32\n",
            "      shape: (-1, 1)\n",
            "      name: StatefulPartitionedCall:1\n",
            "  outputs['log_probs'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 1)\n",
            "      name: StatefulPartitionedCall:2\n",
            "  outputs['tokens'] tensor_info:\n",
            "      dtype: DT_STRING\n",
            "      shape: (-1, 1, -1)\n",
            "      name: StatefulPartitionedCall:3\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BasMT1cvw2_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adfbf8c2-7d6e-495c-a83a-a664251bb74b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['serving_default']\n"
          ]
        }
      ],
      "source": [
        "loadedd = tf.saved_model.load('/content/gdrive/MyDrive/MT')\n",
        "print(list(loadedd.signatures.keys()))  # [\"serving_default\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDPCwPJYtbPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166931b8-3056-4e82-e3ee-5f4f517ad8d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'log_probs': TensorSpec(shape=(None, 1), dtype=tf.float32, name='log_probs'), 'alignment': TensorSpec(shape=(None, 1, None, None), dtype=tf.float32, name='alignment'), 'length': TensorSpec(shape=(None, 1), dtype=tf.int32, name='length'), 'tokens': TensorSpec(shape=(None, 1, None), dtype=tf.string, name='tokens')}\n"
          ]
        }
      ],
      "source": [
        "infer = loadedd.signatures[\"serving_default\"]\n",
        "print(infer.structured_outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loadedd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV-R6906o0rc",
        "outputId": "6b4ed101-de46-43b0-e7e5-0073b7f32139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7fa0f6559160>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8J-7-6Zx7kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbe9c7a-cdf5-42fa-e726-aa3435656228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'log_probs': TensorSpec(shape=(None, 1), dtype=tf.float32, name='log_probs'), 'alignment': TensorSpec(shape=(None, 1, None, None), dtype=tf.float32, name='alignment'), 'length': TensorSpec(shape=(None, 1), dtype=tf.int32, name='length'), 'tokens': TensorSpec(shape=(None, 1, None), dtype=tf.string, name='tokens')}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "infer = loadedd.signatures[\"serving_default\"]\n",
        "print(infer.structured_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ThXnicZx7nl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "ffcacda7-85f8-4501-ea16-e487069db7b0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d577daa308a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs = {\n\u001b[0;32m----> 2\u001b[0;31m             \u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0;34m\"length\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         }\n",
            "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
          ]
        }
      ],
      "source": [
        "inputs = {\n",
        "            \"tokens\": tf.constant(b, dtype=tf.string),\n",
        "            \"length\": tf.constant([5], dtype=tf.int32),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecyjqV82x7ud"
      },
      "outputs": [],
      "source": [
        "infer(**inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSGDU_N4yJMs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}